{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Capstone Project - Immigration Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Table of contents\n",
    "0. Imports and environment configurations\n",
    "1. Data sources\n",
    "2. Data model to implement\n",
    "3. Connect to S3\n",
    "4. Extract, Transform and Load to S3\n",
    "5. Create data dictionaries\n",
    "6. Quality check data\n",
    "7. Load data to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 0. Imports and environment configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 0.1 Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "First we import packages for data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Next we import packages for cloud configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import psycopg2\n",
    "import configparser\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Finally we update the environment to be able to write data to S3 storage in Amazon Web Services (AWS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 0.2 Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('data_model/dwh.cfg'))\n",
    "\n",
    "KEY = config.get('AWS', 'KEY')\n",
    "SECRET = config.get('AWS', 'SECRET')\n",
    "REGION = config.get('AWS', 'REGION')\n",
    "\n",
    "import os\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = KEY\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = SECRET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 0.3 Setting up a spark connection\n",
    "The spark connection has to read data from a specific directory, \"saurfang...\" and also write data to S3 directories, hence the multiple configs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "  .config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\") \\\n",
    "  .config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11,org.apache.hadoop:hadoop-aws:2.7.2\") \\\n",
    "  .enableHiveSupport() \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The cloud infrastructure will be set up later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 1. Data Sources\n",
    "In this project, we build an etl pipeline that extracts data residing in SAS and CSV files, transforms that data, and loads it into a snowflake schema designed for flexible querying. \n",
    "\n",
    "Ultimately, we are building a data model that will give the client easy access to query their data. The client here may be anyone with an interest in immigration data, and the end purpose is to allow the client's analytics team to query the data ad hoc for simple analyses, or to integrate the data in a bigger flow to support automated analyses.\n",
    "\n",
    "We have four data sets consisting of a main, denormalised immigration data table, and supporting tables:\n",
    "1. Immigration data (sas7bdat)\n",
    "2. Temperate data (CSV)\n",
    "3. Demographics data (CSV)\n",
    "4. Airport data (CSV)\n",
    "\n",
    "In addition, for dataset (1) we have a description file to translate code into meaningful text. This file is parched to relate code values to the meaningful text, and for a single code, departure codes, a Google search has been used. This information will expand the data model with one more source of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 1.1 Immigration data\n",
    "This data set holds data relating to immigration to the US. The focal field is the ID (cicid) for each immigration case to the US. In addition, the table holds information on the person related to the case, how and where this person arrived to the US, which date the person arrived respectively was granted admission, and if this person left again.\n",
    "\n",
    "This table will be split into four tables consisting of a fact table and three dimension tables describing the person dimension, the arrival dimension and the visa dimension. Togerher with a description file, we will further extend each of these tables with translation of various abbrevations (codes) into human readable values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.1.0 Extracting the data from the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immi_df = spark \\\n",
    "    .read \\\n",
    "    .format('com.github.saurfang.sas.spark') \\\n",
    "    .load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immi_df.createOrReplaceTempView('immi_raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.1.1 Describing the data\n",
    "We see several field names that are far from interpretable. We also see data types (numericals in particular, but also dates) that are inappropriate from a business perspective.\n",
    "\n",
    "Overall, we can group data into facts, arrival, personal, and visa related data. This observation will be the foundation of the data model, see section 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>None</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20130811</td>\n",
       "      <td>SEO</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN    None   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa entdepd  \\\n",
       "0      NaN    37.0      2.0    1.0      None     None  None       T    None   \n",
       "1      NaN    25.0      3.0    1.0  20130811      SEO  None       G    None   \n",
       "2  20691.0    55.0      2.0    1.0  20160401     None  None       T       O   \n",
       "3  20567.0    28.0      2.0    1.0  20160401     None  None       O       O   \n",
       "4  20567.0     4.0      2.0    1.0  20160401     None  None       O       O   \n",
       "\n",
       "  entdepu matflag  biryear   dtaddto gender insnum airline        admnum  \\\n",
       "0       U    None   1979.0  10282016   None   None    None  1.897628e+09   \n",
       "1       Y    None   1991.0       D/S      M   None    None  3.736796e+09   \n",
       "2    None       M   1961.0  09302016      M   None      OS  6.666432e+08   \n",
       "3    None       M   1988.0  09302016   None   None      AA  9.246846e+10   \n",
       "4    None       M   2012.0  09302016   None   None      AA  9.246846e+10   \n",
       "\n",
       "   fltno visatype  \n",
       "0   None       B2  \n",
       "1  00296       F1  \n",
       "2     93       B2  \n",
       "3  00199       B2  \n",
       "4  00199       B2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immi_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 1.2 Temperature data\n",
    "The temperature data provides information on average temperature measurements in cities around the world from 1743 and onwards. Two fields combine to make a foreign key, Latitude and Longitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.2.0 Extracting the data from the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_df = spark.read \\\n",
    "  .option('header', 'true') \\\n",
    "  .option('inferSchema', 'true') \\\n",
    "  .csv('../../data2/GlobalLandTemperaturesByCity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_df.createOrReplaceTempView('temp_raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.2.1 Describing the data\n",
    "The temperature data provides information on average temperature measurements in cities around the world from November 1st, 1743 and onwards. \n",
    "\n",
    "The data set will be split according to two fact types, (1) being the data and temperature, and (2) being the city and it's location in latitude and longitude. The split allows for a normalisation such that city information isn't repeated for every single temperate observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0 1743-11-01               6.068                          1.737  Århus   \n",
       "1 1743-12-01                 NaN                            NaN  Århus   \n",
       "2 1744-01-01                 NaN                            NaN  Århus   \n",
       "3 1744-02-01                 NaN                            NaN  Århus   \n",
       "4 1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 1.3 Demographics data\n",
    "This table holds information on city populations with respect to age, male/female population, veteran and foreign-born population, and race statistics. The race statistics are registered in a long-format, such that all other statistics are repeated for each race that the city has measurements for. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.3.0 Extracting the data from the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demo_df = spark.read.option(\"delimiter\", \";\").csv('other_data/us-cities-demographics.csv', inferSchema='true', header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demo_df.createOrReplaceTempView('demo_raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.3.1 Describing the data\n",
    "\n",
    "As mentioned above, the table structure calls for a normalised which requires at least two tables. Here, the split goes into three tables:\n",
    "1. A table not holding race statistics\n",
    "2. A table holding race statistics, race being abbreviated into codes\n",
    "3. A table holding abbreviated race codes and the race names associated with each code\n",
    "This separation allows for normalisation of the table.\n",
    "\n",
    "The table connects to immigration data through the state codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8            40601   \n",
       "1            Quincy  Massachusetts        41.0            44129   \n",
       "2            Hoover        Alabama        38.5            38040   \n",
       "3  Rancho Cucamonga     California        34.5            88127   \n",
       "4            Newark     New Jersey        34.6           138040   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0              41862             82463                1562         30908   \n",
       "1              49500             93629                4147         32935   \n",
       "2              46799             84839                4819          8229   \n",
       "3              87105            175232                5821         33878   \n",
       "4             143873            281913                5829         86253   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 1.4 Airport data\n",
    "This data set holds information airports regarding their size, location and elevation etc.\n",
    "\n",
    "The data set connects to the temperature data set through latitude and longitude values (although generally we don't have measurements for airport locations), and additionally we can connect to the immigration data set through IATA_ARPT_CD on visapost. This can only be done under the assumption that the visapost, which is a code for the department that has issued the visa to an immigrant, is done at an airport, and that the code in fact is an IATA_ARPT_CD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.4.0 Extracting the data from the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "arpts_df = spark.read.option(\"header\",\"true\").option('inferSchema', 'true').csv('other_data/airport-codes_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "arpts_df.createOrReplaceTempView('arpts_raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.4.1 Describing the data\n",
    "There are no obvious ways to improve this data, although it can be argued that some fields are redundant. Without more business knowledge it is difficult to know which ones, and hence I keep the data.\n",
    "\n",
    "Generally, ident seems to be similar to gps_code, iata_code and local_code, but there are exceptions everywhere between these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>None</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>None</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>None</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>None</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport            11   \n",
       "1  00AA  small_airport                Aero B Ranch Airport          3435   \n",
       "2  00AK  small_airport                        Lowell Field           450   \n",
       "3  00AL  small_airport                        Epps Airpark           820   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport           237   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0        NA          US      US-PA      Bensalem      00A      None   \n",
       "1        NA          US      US-KS         Leoti     00AA      None   \n",
       "2        NA          US      US-AK  Anchor Point     00AK      None   \n",
       "3        NA          US      US-AL       Harvest     00AL      None   \n",
       "4        NA          US      US-AR       Newport     None      None   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4       None                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arpts_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 1.5 Additional Code tables\n",
    "An additional set of tables can be extracted from a text file. Udacity mentors helped in developing the code. These tables mainly provide translation of abbreviations or code into human readable information. No further comment will be provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('./sas_data/I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "    f_content = f.read()\n",
    "    f_content = f_content.replace('\\t', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def code_mapper(file, idx):\n",
    "    '''\n",
    "    Description\n",
    "    -----------\n",
    "    This function takes a SAS file and a unique word as an \n",
    "    input. The unique word must match a segment of the SAS file \n",
    "    that needs to relate codes to values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file : str\n",
    "        A .SAS file translated to a string.\n",
    "    \n",
    "    idx : str\n",
    "        A string representing a section in the file from which \n",
    "        to extract.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dic : dictionary\n",
    "        A dictionary containing the codes as keys and their \n",
    "        translation as values.\n",
    "    '''\n",
    "    # First, extract everything after the key word\n",
    "    f_content_2 = f_content[f_content.index(idx):]\n",
    "    \n",
    "    # Second, remove anything after the key word table\n",
    "    f_content_2 = f_content_2[:f_content_2.index(';')].split('\\n')\n",
    "    \n",
    "    # Third, remove empty quotation marks\n",
    "    f_content_2 = [i.replace(\"'\",\"\") for i in f_content_2]\n",
    "    \n",
    "    # Fourth, get list pairs of key and values\n",
    "    dic = [i.split('=') for i in f_content_2[1:]]\n",
    "    \n",
    "    # Fifth, turn keys and values into dictionary\n",
    "    dic = dict([i[0].strip(), i[1].strip()] for i in dic if len(i) == 2)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The extraction of the data will also be the transformation, so this will take place in section 2. Data Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 2. Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The data model covers taking the sourced data and normalising it by structuring the data into a star schema. \n",
    "\n",
    "As was covered in section 1 the data is loaded from several sources:\n",
    "1. Immigration data\n",
    "2. Temperature data\n",
    "3. Demographics data\n",
    "4. Airports data\n",
    "5. Text file with documentation\n",
    "\n",
    "There will be a heavy focus on field naming conventions to facilitate analysis. Thus we have some standards:\n",
    "- CD: Fields holding abbreviations such as AL end in CD to indicate they are a code for some meaning. E.g. AL is a state code for the state name Alabama.\n",
    "- DT: Dates are the format 'YYYY-MM-DD' such as '2999-12-31'\n",
    "- ID: These are integer fields always and hold an identification number such as IMM_ID being the identification number for an immigration case.\n",
    "- NM: These fields are descriptive names that don't need interpretation, such as Alabama being a state name.\n",
    "- YR: An integer-field describing the year.\n",
    "- NO: Numerical fields much like ID but where the number might not be sufficiently unique to mark an ID\n",
    "- AMT: Numerical field which holds amounts typically in a decimal form such as a bank balance amt.\n",
    "\n",
    "In general, the field names are abbreviated to three or four-letter words ending in one of the four suffixes above unless it is clear what the name holds such as 'AGE' where it seems excessive to say 'AGE_YR'.\n",
    "\n",
    "**Immigration data**\n",
    "\n",
    "The main tables are a snowflake set of tables with an immigration fact table in the center surrounded by immigration dimension tables. All immigration data have code fields (\"\\_CD\") that refer to some abbreviation or ID that can be decoded. To decode these, a set of CODE-tables have been set up that link to the immigration tables.\n",
    "\n",
    "**Supplementary data**\n",
    "\n",
    "In addition to the immigration tables we have tables that don't directly link to the Immigration data set. These data sets are temperature, demographics and airports data. Each have been normalised to the most reasonable degree. See the graph underneath to get an idea of the entities' relationships.\n",
    "\n",
    "A difficult decision was whether or not to extract code fields to separate tables or translate them directly in the table. For this data model it was decided that the code-fields should reside in separate tables, which could eventually all be combined to one large code-table holding a field for domain, a field for code value and a field for the corresponding meaning of the code value.\n",
    "\n",
    "**Notes on relationships**\n",
    "\n",
    "Note that although there are tables to decrypt most code-fields, these tables don't necessarily pair well due to a lack of data. E.g. temperature data and airport data both have longitudes and latitudes and should thus be able to pair. In practice, since temperatures aren't generally measured at airports the relationships are impaired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "![Image of Immigration Data Model](data_model/imm_data.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 3. Connect to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The aim is to store the data to S3 in parquet files. This requires a few steps as outlined below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3.1 AWS IAM user\n",
    "\n",
    "We need an IAM user with a key and a secret to create an S3 bucket programmatically.\n",
    "\n",
    "1. Create a new `IAM user` in AWS\n",
    "2. Provide `AdministratorAccess` from `Attach existing policies directly` tab\n",
    "3. Copy `Access key` and `Secret`\n",
    "4. Update `dwh.cfg` file with new access key and secret.\n",
    "\n",
    "Note on (4) that the dwh.cfg file has already been loaded. The Notebook needs to be rerun if the key-secret pair needs to change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3.2 Programmatic S3 bucket\n",
    "\n",
    "First the config file needs to be parsed and read and then the clients will be created.\n",
    "\n",
    "1. Create S3 client\n",
    "2. Create S3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2.1 Create S3 client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\n",
    "    's3',\n",
    "    region_name=REGION,\n",
    "    aws_access_key_id=KEY,\n",
    "    aws_secret_access_key=SECRET\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2.2 Create S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If bucket already exists then okay.\n",
      "An error occurred (BucketAlreadyOwnedByYou) when calling the CreateBucket operation: Your previous request to create the named bucket succeeded and you already own it.\n"
     ]
    }
   ],
   "source": [
    "S3_BUCKET = config.get('S3', 'S3_BUCKET')\n",
    "try:\n",
    "    s3.create_bucket(\n",
    "        Bucket='wgram-capstone', \n",
    "        CreateBucketConfiguration={\n",
    "            'LocationConstraint': REGION\n",
    "        }\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"If bucket already exists then okay.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2.3 If we need to delete the bucket\n",
    "\n",
    "Uncomment the below to delete the S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'V7XXYHG78QXPWDM7',\n",
       "  'HostId': '0qA90Gwx0Lp70CGH8sikjfmeVGRCOzqne7QKl1711IX6cFRT47yUxDvURVA8Pl4MYCZXYCDuRJUcSj0nQE27ng==',\n",
       "  'HTTPStatusCode': 204,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '0qA90Gwx0Lp70CGH8sikjfmeVGRCOzqne7QKl1711IX6cFRT47yUxDvURVA8Pl4MYCZXYCDuRJUcSj0nQE27ng==',\n",
       "   'x-amz-request-id': 'V7XXYHG78QXPWDM7',\n",
       "   'date': 'Sun, 12 Jun 2022 21:09:11 GMT',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket = s3.Bucket('wgram-capstone')\n",
    "bucket.objects.all().delete()\n",
    "bucket.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.3 Store files in S3\n",
    "Pandas dataframes write very easily to S3. In order to ensure the format, a set of table specifications written in SQL Data Definition Language (DDL) have been scripted.\n",
    "\n",
    "Because Spark has it's own table specification syntax, a function has been defined to convert SQL DDL to Spark schemas. These are supplied when writing the tables to S3 to ensure the data types. Writing to S3 could be done without the schemas also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.3.1 Define the Schema\n",
    "Below is the function that converts SQL DDL to Spark syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ddl_to_spark_schema(ddl):\n",
    "    '''\n",
    "    Description\n",
    "    -----------\n",
    "    This function takes a SQL DDL script and transforms it\n",
    "    providing a text string that Spark can interpret as a schema.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ddl : str\n",
    "        A string holding a SQL DDL.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    spark_schema : str\n",
    "        A string that can be interpreted as data schema by spark.\n",
    "    '''\n",
    "    \n",
    "    ddl_name = ddl[ddl.find('\\n'):ddl.find('(')] \\\n",
    "      .replace('\\n', '') \\\n",
    "      .split()[0]\n",
    "    \n",
    "    ddl_field_type_list = [txt.strip() for txt in ddl[ddl.find('(')+1:-1] \\\n",
    "      .replace('\\n', '') \\\n",
    "      .replace('PRIMARY KEY', '') \\\n",
    "      .replace(', ', '') \\\n",
    "      .split()\n",
    "    ]\n",
    "    \n",
    "    # Pair field names and data types and join each pair separated by a comma\n",
    "    spark_schema = ', '.join(\n",
    "        [i+' '+j for i, j in zip(ddl_field_type_list[::2], ddl_field_type_list[1::2])]\n",
    "    )\n",
    "    \n",
    "    return {ddl_name : spark_schema}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.3.2 Read the DDL's\n",
    "The DDL's are imported and then turned into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from create_tables import create_data_model_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IMM_FCT': 'IMM_ID INTEGER, ADM_CD CHAR(1), ADM_MTD_CD INTEGER, ADM_NO INTEGER, ADM_DT DATE, DEP_CD CHAR(1), DEP_DT DATE, ADM_UPD_CD CHAR(1)',\n",
       " 'IMM_DIM_PSN': 'IMM_ID INTEGER, INS_ID INTEGER, BRTH_YR INTEGER, AGE INTEGER, OCC_CD CHAR(3), GNDR_CD CHAR(1), CTY_OF_RSDN_ID INTEGER, CTY_OF_CTZ_ID INTEGER, ADR_RGN_CD CHAR(2)',\n",
       " 'IMM_DIM_VISA': 'IMM_ID INTEGER, VISA_TP_CD CHAR(2), VISA_RSN_CD INTEGER, VISA_ISSU_DEP_CD CHAR(3)',\n",
       " 'IMM_DIM_ARPT': 'IMM_ID INTEGER, ARPT_CD CHAR(3), ARLN_CD CHAR(2), FLGT_CD CHAR(5), ARR_DT DATE',\n",
       " 'TEMP_FCT': 'TEMP_CITY_ID INTEGER, TEMP_MSR_DT DATE, TEMP_AVG_VAL DECIMAL(5,3), TEMP_SD_VAL DECIMAL(5,3)',\n",
       " 'TEMP_DIM_CITY': 'TEMP_CITY_ID INTEGER, CITY_NM VARCHAR(255), CTY_NM VARCHAR(255), LAT_VAL DECIMAL(4,2), LONG_VAL DECIMAL(5,2)',\n",
       " 'ARPT_FCT': 'ARPT_ID CHAR(4), ARPT_TP VARCHAR(20), ARPT_NM VARCHAR(255), ELEV_FT DECIMAL(9,2), CONT_CD CHAR(2), ISO_CTY_CD CHAR(2), ISO_RGN_CD CHAR(7), MUNI_NM VARCHAR(255), GPS_CD CHAR(4), IATA_ARPT_CD CHAR(3), LCL_ARPT_CD CHAR(3), LAT_VAL DECIMAL(4,2), LONG_VAL DECIMAL(5,2)',\n",
       " 'DEMO_FCT': 'DEMO_CITY_ID INTEGER, RGN_CD CHAR(2), RGN_NM VARCHAR(255), CITY_NM VARCHAR(255), MED_AGE DECIMAL(4,1), POP_TOT_AMT INTEGER, POP_MLE_AMT INTEGER, POP_FMLE_AMT INTEGER, POP_VET_AMT INTEGER, POP_FGN_AMT INTEGER, AVG_HH_SZ DECIMAL(4,2)',\n",
       " 'DEMO_FCT_RACE': 'DEMO_CITY_ID INTEGER, RACE_TP_CD CHAR(4), POP_RACE_AMT INTEGER',\n",
       " 'CD_RACE_TP': 'RACE_TP_CD CHAR(4), RACE_TP_NM VARCHAR(50)',\n",
       " 'CD_ADM_MTD': 'ADM_MTD_CD CHAR(1), ADM_MTD_NM VARCHAR(100)',\n",
       " 'CD_ADM_ST': 'ADM_ST_CD CHAR(1), ADM_ST_NM VARCHAR(100)',\n",
       " 'CD_ARPT': 'ARPT_CD CHAR(3), ARPT_NM VARCHAR(100), ARPT_STT_CD CHAR(2)',\n",
       " 'CD_CTY': 'CTY_CD CHAR(3), CTY_NM VARCHAR(100)',\n",
       " 'CD_DEP_ST': 'DEP_CD CHAR(1), DEP_NM VARCHAR(150)',\n",
       " 'CD_RGN': 'RGN_CD CHAR(2), RGN_NM VARCHAR(100)',\n",
       " 'CD_VISA_RSN': 'VISA_RSN_CD INTEGER, VISA_RSN_NM VARCHAR(100)'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [ddl_to_spark_schema(ddl) for ddl in create_data_model_tables]\n",
    "schema_dict = {k: v for d in s for k, v in d.items()}\n",
    "schema_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Any output must be written to the following path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "output_data = 's3a://wgram-data-lake-songs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.3.3 Define the write to S3 function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def write_to_s3(df, df_name, partitionBy=[], schema_dict=schema_dict, output_dir='s3a://wgram-data-lake-songs/'):\n",
    "    '''\n",
    "    Description\n",
    "    -----------\n",
    "    This function takes a pandas dataframe and writes it \n",
    "    to S3 storage.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        A Pandas DataFrame\n",
    "    df_name : str\n",
    "        The name of the dataframe\n",
    "    schema_dic : dict\n",
    "        A dictionary of schemas\n",
    "    output_dir : str\n",
    "        The S3 bucket to write to\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    '''\n",
    "    try:\n",
    "        schema = schema_dict[df_name.upper()]\n",
    "    except KeyError as e:\n",
    "        print(\"schema dictionary does not hold a schema with name \" + df_name.upper())\n",
    "        print(f\"Error: {e}\")\n",
    "        return(None)\n",
    "    \n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        try:\n",
    "            df = spark.createDataFrame(df, schema=schema)\n",
    "        except TypeError as e:\n",
    "            print(\"Something went wrong\")\n",
    "            print(f\"Error: {e}\")\n",
    "            return(None)\n",
    "    \n",
    "    if len(partitionBy) == 0:\n",
    "        df \\\n",
    "            .write \\\n",
    "            .mode('overwrite') \\\n",
    "            .parquet(output_dir + df_name + '.parquet')\n",
    "    else:\n",
    "        df \\\n",
    "            .repartition(*partitionBy) \\\n",
    "            .write \\\n",
    "            .mode('overwrite') \\\n",
    "            .partitionBy(*partitionBy) \\\n",
    "            .parquet(output_dir + df_name + '.parquet')\n",
    "    \n",
    "    print(\"File \" + output_dir + df_name + '.parquet' + ' was saved.')\n",
    "    \n",
    "    return(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4. Table creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The tables will be created in the following order:\n",
    "\n",
    "0. Code data\n",
    "1. Airport data\n",
    "2. Demographics data\n",
    "3. Temperature data\n",
    "4. Immigration (i94) data\n",
    "\n",
    "In each step we will model the source data into their respective tables including necessary transformations and allocation of a key field. Then we will write the file to parquet which makes for easy storage in S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.0 Code data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.0.1 ARPT_CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dic = code_mapper(f_content, 'i94prtl')\n",
    "\n",
    "cd_arpt = pd.DataFrame \\\n",
    "    .from_dict(dic, orient='index') \\\n",
    "    .reset_index() \\\n",
    "    .rename(columns = {'index':'ARPT_CD', 0:'ARPT_NM'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cd_arpt['ARPT_STT_CD'] = cd_arpt.ARPT_NM.str.split(pat=',', n = -1, expand=True)[1].str[1:3]\n",
    "cd_arpt.ARPT_NM = cd_arpt.ARPT_NM.str.split(pat=',', n = -1, expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARPT_CD</th>\n",
       "      <th>ARPT_NM</th>\n",
       "      <th>ARPT_STT_CD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ARPT_CD                   ARPT_NM ARPT_STT_CD\n",
       "0     ALC                     ALCAN          AK\n",
       "1     ANC                 ANCHORAGE          AK\n",
       "2     BAR  BAKER AAF - BAKER ISLAND          AK\n",
       "3     DAC             DALTONS CACHE          AK\n",
       "4     PIZ    DEW STATION PT LAY DEW          AK"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd_arpt.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "write_to_s3(cd_arpt, 'cd_arpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.0.2 CTY_CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dic = code_mapper(f_content, 'i94cntyl')\n",
    "\n",
    "cd_cty = pd.DataFrame \\\n",
    "    .from_dict(dic, orient='index') \\\n",
    "    .reset_index() \\\n",
    "    .rename(columns = {'index':'CTY_CD', 0:'CTY_NM'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CTY_CD</th>\n",
       "      <th>CTY_NM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CTY_CD                                             CTY_NM\n",
       "0    582  MEXICO Air Sea, and Not Reported (I-94, no lan...\n",
       "1    236                                        AFGHANISTAN\n",
       "2    101                                            ALBANIA\n",
       "3    316                                            ALGERIA\n",
       "4    102                                            ANDORRA"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd_cty.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File s3a://wgram-data-lake-songs/cd_cty.parquet was saved.\n"
     ]
    }
   ],
   "source": [
    "write_to_s3(cd_cty, 'cd_cty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.0.3 ADM_MTD_CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dic = code_mapper(f_content, 'i94model')\n",
    "\n",
    "cd_adm_mtd = pd.DataFrame \\\n",
    "    .from_dict(dic, orient='index') \\\n",
    "    .reset_index() \\\n",
    "    .rename(columns = {'index':'ADM_MTD_CD', 0:'ADM_MTD_NM'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADM_MTD_CD</th>\n",
       "      <th>ADM_MTD_NM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Not reported</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ADM_MTD_CD    ADM_MTD_NM\n",
       "0          1           Air\n",
       "1          2           Sea\n",
       "2          3          Land\n",
       "3          9  Not reported"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd_adm_mtd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something went wrong\n",
      "Error: field ADM_MTD_CD: IntegerType can not accept object '1' in type <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "write_to_s3(cd_adm_mtd, 'cd_adm_mtd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.0.4 RGN_CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dic = code_mapper(f_content, 'i94addrl')\n",
    "\n",
    "cd_rgn = pd.DataFrame \\\n",
    "    .from_dict(dic, orient='index') \\\n",
    "    .reset_index() \\\n",
    "    .rename(columns = {'index':'RGN_CD', 0:'RGN_NM'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RGN_CD</th>\n",
       "      <th>RGN_NM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RGN_CD      RGN_NM\n",
       "0     AL     ALABAMA\n",
       "1     AK      ALASKA\n",
       "2     AZ     ARIZONA\n",
       "3     AR    ARKANSAS\n",
       "4     CA  CALIFORNIA"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd_rgn.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "write_to_s3(cd_rgn, 'cd_rgn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.0.5 VISA_RSN_CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dic = code_mapper(f_content, 'I94VISA')\n",
    "\n",
    "cd_visa_rsn = pd.DataFrame \\\n",
    "    .from_dict(dic, orient='index') \\\n",
    "    .reset_index() \\\n",
    "    .rename(columns = {'index':'VISA_RSN_CD', 0:'VISA_RSN_NM'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VISA_RSN_CD</th>\n",
       "      <th>VISA_RSN_NM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Student</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  VISA_RSN_CD VISA_RSN_NM\n",
       "0           1    Business\n",
       "1           2    Pleasure\n",
       "2           3     Student"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd_visa_rsn.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema dictionary does not hold a schema with name CD_VISA_RSN\n",
      "Error: 'CD_VISA_RSN'\n"
     ]
    }
   ],
   "source": [
    "write_to_s3(cd_visa_rsn, 'cd_visa_rsn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.0.6 Additional Code Tables\n",
    "From Udacity forums we were provided with inputs to CD_ADM_ST and from Google we could hypothesise on values for CD_DEP_ST. We could not get a clear answer regarding the latter on the forums unfortunately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.0.6.1 CD_ADM_ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "enta_flags = {\n",
    "    'G':'Admitted into US', \n",
    "    'O':'Paroled into US', \n",
    "    'R':'Departed',\n",
    "    'K':'Lost I94 or is deceased',\n",
    "    'N':'Apprehended',\n",
    "    'T':'Overstayed',\n",
    "    'Z':'Adjusted to per residence'\n",
    "}\n",
    "\n",
    "cd_adm_st = pd.DataFrame \\\n",
    "    .from_dict(enta_flags, orient='index') \\\n",
    "    .reset_index() \\\n",
    "    .rename(columns = {'index':'ADM_ST_CD', 0:'ADM_ST_NM'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADM_ST_CD</th>\n",
       "      <th>ADM_ST_NM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G</td>\n",
       "      <td>Admitted into US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O</td>\n",
       "      <td>Paroled into US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>Departed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K</td>\n",
       "      <td>Lost I94 or is deceased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "      <td>Apprehended</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ADM_ST_CD                ADM_ST_NM\n",
       "0         G         Admitted into US\n",
       "1         O          Paroled into US\n",
       "2         R                 Departed\n",
       "3         K  Lost I94 or is deceased\n",
       "4         N              Apprehended"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd_adm_st.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File s3a://wgram-data-lake-songs/cd_adm_st.parquet was saved.\n"
     ]
    }
   ],
   "source": [
    "write_to_s3(cd_adm_st, 'cd_adm_st')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.0.6.2 CD_DEP_ST\n",
    "\n",
    "The departure flag seems farfetched, but I kept returning to the below site, which seemed to have something interpretable. I asked about it on the forum but to no avail. Hence the mappings should be accepted only cautiously if at all.\n",
    "\n",
    "https://www.dshs.wa.gov/sites/default/files/ESA/eaz-manual/USCIS%20I-94%20Table.pdf\n",
    "\n",
    "Another source could be the following, but again - there is a lack of verification:\n",
    "https://www.dhs.gov/immigration-statistics/lawful-permanent-residents/ImmigrantCOA\n",
    "\n",
    "And other sources which uses the same codes as the first link:\n",
    "https://www.dhs.gov/immigration-statistics/special-reports/legal-immigration\n",
    "https://www.dickinson-wright.com/practice-areas/immigration-services?tab=0\n",
    "https://travel.state.gov/content/dam/visas/Statistics/Immigrant-Statistics/MonthlyIVIssuances/Immigrant%20Visa%20Symbols.pdf\n",
    "\n",
    "I want to reconciliate with the following Dashboard:\n",
    "https://www.trade.gov/data-visualization/adisi-94-visitor-arrivals-monitor-cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "entd_flags = {\n",
    "    'D': 'Alien crewman.',\n",
    "    'I': 'Representative of foreign information media, spouse and children.',\n",
    "    'J': 'Exchange visitor or spose or child thereof.',\n",
    "    'K': \"Relating to a marriage contract or as an immediate relative \\\n",
    "of a U.S. citizen (I-130).\",\n",
    "    'L': 'Intercompany transferee',\n",
    "    'M': 'Student pursuing a full course of study at an established \\\n",
    "vocational or other recognized nonacademic institution.',\n",
    "    'N': 'Parent of an alien classified SK3 or SN3 or Child of \\\n",
    "N-8 or of an alien classified SK1, SK2, SK4, SN1, SN2, or SN4.',\n",
    "    'O': 'Temporary worker with extraordinary ability/achievement in \\\n",
    "the sciences, arts, education, business, or athletics.',\n",
    "    'Q': 'Temporary worker in an international cultural exchange program',\n",
    "    'R': 'Temporary worker to perform work in religious occupations.',\n",
    "    'V': 'Nonimmigrant spouse of lawful permanent \\\n",
    "residents relating to the LIFE Act, as of December 28, 2000.',\n",
    "    'W': 'Temporary visitor for under the Visa Waiver Program.'\n",
    "}\n",
    "\n",
    "cd_dep = pd.DataFrame \\\n",
    "    .from_dict(entd_flags, orient='index') \\\n",
    "    .reset_index() \\\n",
    "    .rename(columns = {'index':'DEP_CD', 0:'DEP_CD_NM'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEP_CD</th>\n",
       "      <th>DEP_CD_NM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D</td>\n",
       "      <td>Alien crewman.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>Representative of foreign information media, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J</td>\n",
       "      <td>Exchange visitor or spose or child thereof.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K</td>\n",
       "      <td>Relating to a marriage contract or as an immed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L</td>\n",
       "      <td>Intercompany transferee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DEP_CD                                          DEP_CD_NM\n",
       "0      D                                     Alien crewman.\n",
       "1      I  Representative of foreign information media, s...\n",
       "2      J        Exchange visitor or spose or child thereof.\n",
       "3      K  Relating to a marriage contract or as an immed...\n",
       "4      L                            Intercompany transferee"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd_dep.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "write_to_s3(cd_dep, 'cd_dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.0.7 Codes dataframe dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "df_dict_cd = {\n",
    "    'CD_ARPT': cd_arpt,\n",
    "    'CD_CTY': cd_cty,\n",
    "    'CD_ADM_MTD': cd_adm_mtd,\n",
    "    'CD_RGN': cd_rgn,\n",
    "    'CD_VISA_RSN': cd_visa_rsn,\n",
    "    'CD_ADM_ST': cd_adm_st,\n",
    "    'CD_DEP': cd_dep\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.1 Airport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "arpt_fct = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT \n",
    "        CAST(ard.ident                        AS CHAR(4))      AS ARPT_ID      ,\n",
    "        CAST(INITCAP(REPLACE(type, '_', ' ')) AS VARCHAR(20))  AS ARPT_TP      ,\n",
    "        CAST(name                             AS VARCHAR(255)) AS ARPT_NM      ,\n",
    "        CAST(elevation_ft                     AS DECIMAL(9,2)) AS ELEV_FT      ,\n",
    "        CAST(continent                        AS CHAR(2))      AS CONT_CD      ,\n",
    "        CAST(iso_country                      AS CHAR(2))      AS ISO_CTY_CD   ,\n",
    "        CAST(iso_region                       AS CHAR(7))      AS ISO_RGN_CD   ,\n",
    "        CAST(municipality                     AS VARCHAR(255)) AS MUNI_NM      ,\n",
    "        CAST(gps_code                         AS CHAR(4))      AS GPS_CD       ,\n",
    "        CAST(iata_code                        AS CHAR(3))      AS IATA_ARPT_CD ,\n",
    "        CAST(local_code                       AS CHAR(3))      AS LCL_ARPT_CD  ,\n",
    "        CAST(trim(split(coordinates, ',')[1]) AS DECIMAL(4,2)) AS LAT_VAL      ,\n",
    "        CAST(trim(split(coordinates, ',')[0]) AS DECIMAL(5,2)) AS LONG_VAL\n",
    "    FROM arpts_raw AS ard\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARPT_ID</th>\n",
       "      <th>ARPT_TP</th>\n",
       "      <th>ARPT_NM</th>\n",
       "      <th>ELEV_FT</th>\n",
       "      <th>CONT_CD</th>\n",
       "      <th>ISO_CTY_CD</th>\n",
       "      <th>ISO_RGN_CD</th>\n",
       "      <th>MUNI_NM</th>\n",
       "      <th>GPS_CD</th>\n",
       "      <th>IATA_ARPT_CD</th>\n",
       "      <th>LCL_ARPT_CD</th>\n",
       "      <th>LAT_VAL</th>\n",
       "      <th>LONG_VAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00TS</td>\n",
       "      <td>Small Airport</td>\n",
       "      <td>Alpine Range Airport</td>\n",
       "      <td>670.00</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Everman</td>\n",
       "      <td>00TS</td>\n",
       "      <td>None</td>\n",
       "      <td>00TS</td>\n",
       "      <td>32.61</td>\n",
       "      <td>-97.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03VA</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Whipoorwill Springs Airport</td>\n",
       "      <td>250.00</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-VA</td>\n",
       "      <td>Nokesville</td>\n",
       "      <td>03VA</td>\n",
       "      <td>None</td>\n",
       "      <td>03VA</td>\n",
       "      <td>38.66</td>\n",
       "      <td>-77.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04NJ</td>\n",
       "      <td>Small Airport</td>\n",
       "      <td>Emmanuel Airport</td>\n",
       "      <td>155.00</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-NJ</td>\n",
       "      <td>Elmer</td>\n",
       "      <td>04NJ</td>\n",
       "      <td>None</td>\n",
       "      <td>04NJ</td>\n",
       "      <td>39.60</td>\n",
       "      <td>-75.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07Y</td>\n",
       "      <td>Small Airport</td>\n",
       "      <td>Hill City-Quadna Mountain Airport</td>\n",
       "      <td>1289.00</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MN</td>\n",
       "      <td>Hill City</td>\n",
       "      <td>07Y</td>\n",
       "      <td>None</td>\n",
       "      <td>07Y</td>\n",
       "      <td>46.96</td>\n",
       "      <td>-93.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0AK9</td>\n",
       "      <td>Small Airport</td>\n",
       "      <td>Falcon Lake Strip</td>\n",
       "      <td>110.00</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Point Mackenzie</td>\n",
       "      <td>0AK9</td>\n",
       "      <td>None</td>\n",
       "      <td>0AK9</td>\n",
       "      <td>61.33</td>\n",
       "      <td>-150.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ARPT_ID        ARPT_TP                            ARPT_NM  ELEV_FT CONT_CD  \\\n",
       "0    00TS  Small Airport               Alpine Range Airport   670.00      NA   \n",
       "1    03VA         Closed        Whipoorwill Springs Airport   250.00      NA   \n",
       "2    04NJ  Small Airport                   Emmanuel Airport   155.00      NA   \n",
       "3     07Y  Small Airport  Hill City-Quadna Mountain Airport  1289.00      NA   \n",
       "4    0AK9  Small Airport                  Falcon Lake Strip   110.00      NA   \n",
       "\n",
       "  ISO_CTY_CD ISO_RGN_CD          MUNI_NM GPS_CD IATA_ARPT_CD LCL_ARPT_CD  \\\n",
       "0         US      US-TX          Everman   00TS         None        00TS   \n",
       "1         US      US-VA       Nokesville   03VA         None        03VA   \n",
       "2         US      US-NJ            Elmer   04NJ         None        04NJ   \n",
       "3         US      US-MN        Hill City    07Y         None         07Y   \n",
       "4         US      US-AK  Point Mackenzie   0AK9         None        0AK9   \n",
       "\n",
       "  LAT_VAL LONG_VAL  \n",
       "0   32.61   -97.24  \n",
       "1   38.66   -77.58  \n",
       "2   39.60   -75.23  \n",
       "3   46.96   -93.60  \n",
       "4   61.33  -150.06  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arpt_fct.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File s3a://wgram-data-lake-songs/arpt_fct.parquet was saved.\n"
     ]
    }
   ],
   "source": [
    "write_to_s3(arpt_fct, 'arpt_fct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.1.2 Airport dataframe dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_dict_arpt = {'ARPT_FCT': arpt_fct}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.2 Demographics data\n",
    "This data set will be split into three data sets in order to normalise the data.\n",
    "\n",
    "1. DEMO_FCT that holds general population facts for each city\n",
    "2. DEMO_RACE_FCT that holds population facts for each relevant race in each city\n",
    "3. CD_RACE_TP that holds codes translating race types from code to their translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2.1 DEMO_FCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demo_fct = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        ROW_NUMBER() OVER (PARTITION BY '' ORDER BY '') AS DEMO_CITY_ID,\n",
    "        tmp.*\n",
    "    FROM (\n",
    "    SELECT DISTINCT \n",
    "        CAST(`State Code`             AS CHAR(2)      ) AS RGN_CD,\n",
    "        CAST(State                    AS VARCHAR(255) ) AS RGN_NM,\n",
    "        CAST(City                     AS VARCHAR(255) ) AS CITY_NM,\n",
    "        CAST(`Median Age`             AS DECIMAL(4,1) ) AS MED_AGE,\n",
    "        CAST(`Total Population`       AS INTEGER      ) AS POP_TOT_AMT,\n",
    "        CAST(`Male Population`        AS INTEGER      ) AS POP_MLE_AMT,\n",
    "        CAST(`Female Population`      AS INTEGER      ) AS POP_FMLE_AMT,\n",
    "        CAST(`Number of Veterans`     AS INTEGER      ) AS POP_VET_AMT,\n",
    "        CAST(`Foreign-born`           AS INTEGER      ) AS POP_FGN_AMT,\n",
    "        CAST(`Average Household Size` AS DECIMAL(4,2) ) AS AVG_HH_SZ\n",
    "    FROM demo_raw AS drd\n",
    "    ) AS tmp\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demo_fct.createOrReplaceTempView('demo_fct_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEMO_CITY_ID</th>\n",
       "      <th>RGN_CD</th>\n",
       "      <th>RGN_NM</th>\n",
       "      <th>CITY_NM</th>\n",
       "      <th>MED_AGE</th>\n",
       "      <th>POP_TOT_AMT</th>\n",
       "      <th>POP_MLE_AMT</th>\n",
       "      <th>POP_FMLE_AMT</th>\n",
       "      <th>POP_VET_AMT</th>\n",
       "      <th>POP_FGN_AMT</th>\n",
       "      <th>AVG_HH_SZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MO</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>Independence</td>\n",
       "      <td>38.6</td>\n",
       "      <td>117255</td>\n",
       "      <td>54348</td>\n",
       "      <td>62907</td>\n",
       "      <td>10220</td>\n",
       "      <td>4911</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CO</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Colorado Springs</td>\n",
       "      <td>34.8</td>\n",
       "      <td>456562</td>\n",
       "      <td>225544</td>\n",
       "      <td>231018</td>\n",
       "      <td>49291</td>\n",
       "      <td>35320</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MA</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>31.5</td>\n",
       "      <td>110402</td>\n",
       "      <td>55421</td>\n",
       "      <td>54981</td>\n",
       "      <td>2495</td>\n",
       "      <td>27757</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>LA</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>Metairie</td>\n",
       "      <td>41.6</td>\n",
       "      <td>146458</td>\n",
       "      <td>69515</td>\n",
       "      <td>76943</td>\n",
       "      <td>7187</td>\n",
       "      <td>19871</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>Santa Clarita</td>\n",
       "      <td>38.1</td>\n",
       "      <td>182367</td>\n",
       "      <td>90192</td>\n",
       "      <td>92175</td>\n",
       "      <td>8537</td>\n",
       "      <td>40666</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DEMO_CITY_ID RGN_CD         RGN_NM           CITY_NM MED_AGE  POP_TOT_AMT  \\\n",
       "0             1     MO       Missouri      Independence    38.6       117255   \n",
       "1             2     CO       Colorado  Colorado Springs    34.8       456562   \n",
       "2             3     MA  Massachusetts         Cambridge    31.5       110402   \n",
       "3             4     LA      Louisiana          Metairie    41.6       146458   \n",
       "4             5     CA     California     Santa Clarita    38.1       182367   \n",
       "\n",
       "   POP_MLE_AMT  POP_FMLE_AMT  POP_VET_AMT  POP_FGN_AMT AVG_HH_SZ  \n",
       "0        54348         62907        10220         4911      2.33  \n",
       "1       225544        231018        49291        35320      2.48  \n",
       "2        55421         54981         2495        27757      2.06  \n",
       "3        69515         76943         7187        19871      2.39  \n",
       "4        90192         92175         8537        40666      3.02  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_fct.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2.2 DEMO_FCT_RACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demo_fct_race = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        ddd.DEMO_CITY_ID, \n",
    "        drd.RACE_TP_CD,\n",
    "        drd.POP_RACE_AMT\n",
    "    FROM (\n",
    "    SELECT DISTINCT \n",
    "        CAST(`State Code`           AS CHAR(2))      AS RGN_CD,\n",
    "        CAST(City AS VARCHAR(255))  AS CITY_NM,\n",
    "        CASE Race\n",
    "            WHEN 'American Indian and Alaska Native' THEN 'AIAN'\n",
    "            WHEN 'Hispanic or Latino'                THEN 'HILA'\n",
    "            WHEN 'Black or African-American'         THEN 'BLAA'\n",
    "            WHEN 'Asian'                             THEN 'ASAN'\n",
    "            WHEN 'White'                             THEN 'WHTE'\n",
    "            ELSE 'UNKN'\n",
    "        END AS RACE_TP_CD,\n",
    "        CAST(Count AS INTEGER) AS POP_RACE_AMT\n",
    "    FROM demo_raw AS drd\n",
    "    ) AS drd\n",
    "    INNER JOIN demo_fct_df AS ddd\n",
    "        ON  1=1\n",
    "        AND drd.RGN_CD = ddd.RGN_CD\n",
    "        AND drd.CITY_NM = ddd.CITY_NM\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEMO_CITY_ID</th>\n",
       "      <th>RACE_TP_CD</th>\n",
       "      <th>POP_RACE_AMT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>309</td>\n",
       "      <td>WHTE</td>\n",
       "      <td>52445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>447</td>\n",
       "      <td>BLAA</td>\n",
       "      <td>138242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>BLAA</td>\n",
       "      <td>9221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>208</td>\n",
       "      <td>BLAA</td>\n",
       "      <td>5294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>363</td>\n",
       "      <td>AIAN</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DEMO_CITY_ID RACE_TP_CD  POP_RACE_AMT\n",
       "0           309       WHTE         52445\n",
       "1           447       BLAA        138242\n",
       "2            73       BLAA          9221\n",
       "3           208       BLAA          5294\n",
       "4           363       AIAN           845"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_fct_race.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2.3 Demographics race codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cd_race_tp = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT \n",
    "        CASE Race\n",
    "            WHEN 'American Indian and Alaska Native' THEN 'AIAN'\n",
    "            WHEN 'Hispanic or Latino'                THEN 'HILA'\n",
    "            WHEN 'Black or African-American'         THEN 'BLAA'\n",
    "            WHEN 'Asian'                             THEN 'ASAN'\n",
    "            WHEN 'White'                             THEN 'WHTE'\n",
    "            ELSE 'UNKN'\n",
    "        END AS RACE_TP_CD,\n",
    "        CAST(Race AS VARCHAR(255)) AS RACE_TP\n",
    "    FROM demo_raw AS drd\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RACE_TP_CD</th>\n",
       "      <th>RACE_TP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASAN</td>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIAN</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HILA</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLAA</td>\n",
       "      <td>Black or African-American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WHTE</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RACE_TP_CD                            RACE_TP\n",
       "0       ASAN                              Asian\n",
       "1       AIAN  American Indian and Alaska Native\n",
       "2       HILA                 Hispanic or Latino\n",
       "3       BLAA          Black or African-American\n",
       "4       WHTE                              White"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd_race_tp.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2.4 Save to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File s3a://wgram-data-lake-songs/demo_fct.parquet was saved.\n"
     ]
    }
   ],
   "source": [
    "write_to_s3(demo_fct, 'demo_fct', partitionBy=['RGN_CD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File s3a://wgram-data-lake-songs/demo_fct_race.parquet was saved.\n"
     ]
    }
   ],
   "source": [
    "write_to_s3(demo_fct_race, 'demo_fct_race', partitionBy=['RACE_TP_CD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File s3a://wgram-data-lake-songs/cd_race_tp.parquet was saved.\n"
     ]
    }
   ],
   "source": [
    "write_to_s3(cd_race_tp, 'cd_race_tp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2.4 Demographics dataframe dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_dict_demo = {\n",
    "    'DEMO_FCT': demo_fct.toPandas(),\n",
    "    'DEMO_FCT_RACE': demo_fct_race.toPandas(),\n",
    "    'CD_RACE_TP': cd_race_tp.toPandas()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.3 Temperature data\n",
    "This data set will be split into two tables:\n",
    "1. TEMP_DIM_CITY holding information about each city so that the fact table only holds a city identity key\n",
    "2. CITY_FCT holding the facts for each city key for each measurement date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3.1 Temperature city dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_dim_city = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        ROW_NUMBER() OVER (PARTITION BY '' ORDER BY '') AS TEMP_CITY_ID,\n",
    "        CITY_NM,\n",
    "        CTY_NM,\n",
    "        CAST(LAT_SIGN || LAT_VAL AS DECIMAL(4,2)) LAT_VAL,\n",
    "        CAST(LONG_SIGN || LONG_VAL AS DECIMAL(5,2)) LONG_VAL\n",
    "    FROM (\n",
    "    SELECT DISTINCT \n",
    "        CAST(City as VARCHAR(255)) AS CITY_NM,\n",
    "        CAST(Country as VARCHAR(255)) AS CTY_NM,\n",
    "        MAX(CASE WHEN SUBSTRING(latitude, CHARACTER_LENGTH(latitude), 1) = 'N' THEN '+' ELSE '-' END) AS LAT_SIGN,\n",
    "        MAX(TRIM(SUBSTRING(latitude, 1, CHARACTER_LENGTH(latitude) - 1))) as LAT_VAL,\n",
    "        MAX(CASE WHEN SUBSTRING(longitude, CHARACTER_LENGTH(longitude), 1) = 'N' THEN '+' ELSE '-' END) AS LONG_SIGN,\n",
    "        MAX(TRIM(SUBSTRING(longitude, 1, CHARACTER_LENGTH(longitude) - 1))) as LONG_VAL\n",
    "    FROM temp_raw AS drd\n",
    "    GROUP BY\n",
    "        City,\n",
    "        Country\n",
    "    ) AS TEMP\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_dim_city.createOrReplaceTempView('temp_dim_city_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMP_CITY_ID</th>\n",
       "      <th>CITY_NM</th>\n",
       "      <th>CTY_NM</th>\n",
       "      <th>LAT_VAL</th>\n",
       "      <th>LONG_VAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>United States</td>\n",
       "      <td>34.56</td>\n",
       "      <td>-116.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Fuzhou</td>\n",
       "      <td>China</td>\n",
       "      <td>26.52</td>\n",
       "      <td>-120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Maanshan</td>\n",
       "      <td>China</td>\n",
       "      <td>31.35</td>\n",
       "      <td>-118.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Windhoek</td>\n",
       "      <td>Namibia</td>\n",
       "      <td>-23.31</td>\n",
       "      <td>-16.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ueda</td>\n",
       "      <td>Japan</td>\n",
       "      <td>36.17</td>\n",
       "      <td>-139.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEMP_CITY_ID   CITY_NM         CTY_NM LAT_VAL LONG_VAL\n",
       "0             1   Ontario  United States   34.56  -116.76\n",
       "1             2    Fuzhou          China   26.52  -120.00\n",
       "2             3  Maanshan          China   31.35  -118.74\n",
       "3             4  Windhoek        Namibia  -23.31   -16.60\n",
       "4             5      Ueda          Japan   36.17  -139.23"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dim_city.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File s3a://wgram-data-lake-songs/temp_dim_city.parquet was saved.\n"
     ]
    }
   ],
   "source": [
    "write_to_s3(temp_dim_city, 'temp_dim_city', partitionBy = ['CTY_NM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3.2 Temperature fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_fct = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        dtcd.TEMP_CITY_ID,\n",
    "        trd.MSR_DT,\n",
    "        trd.TEMP_AVG_VAL,\n",
    "        trd.TEMP_SD_VAL\n",
    "    FROM (\n",
    "    SELECT DISTINCT \n",
    "        CAST(dt                            AS DATE)         AS MSR_DT,\n",
    "        CAST(AverageTemperature            AS DECIMAL(5,3)) AS TEMP_AVG_VAL,\n",
    "        CAST(AverageTemperatureUncertainty AS DECIMAL(5,3)) AS TEMP_SD_VAL,\n",
    "        CAST(City                          AS VARCHAR(255)) AS CITY_NM,\n",
    "        CAST(Country                       AS VARCHAR(255)) AS CTY_NM\n",
    "    FROM temp_raw AS trd\n",
    "    ) AS trd\n",
    "    INNER JOIN temp_dim_city_df AS dtcd\n",
    "        ON  1=1\n",
    "        AND trd.CITY_NM = dtcd.CITY_NM\n",
    "        AND trd.CTY_NM = dtcd.CTY_NM\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMP_CITY_ID</th>\n",
       "      <th>MSR_DT</th>\n",
       "      <th>TEMP_AVG_VAL</th>\n",
       "      <th>TEMP_SD_VAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1537</td>\n",
       "      <td>1750-03-01</td>\n",
       "      <td>2.773</td>\n",
       "      <td>2.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1537</td>\n",
       "      <td>1772-04-01</td>\n",
       "      <td>9.009</td>\n",
       "      <td>2.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1537</td>\n",
       "      <td>1797-03-01</td>\n",
       "      <td>2.155</td>\n",
       "      <td>1.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1537</td>\n",
       "      <td>1814-06-01</td>\n",
       "      <td>19.209</td>\n",
       "      <td>1.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1537</td>\n",
       "      <td>1820-01-01</td>\n",
       "      <td>-5.747</td>\n",
       "      <td>8.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEMP_CITY_ID      MSR_DT TEMP_AVG_VAL TEMP_SD_VAL\n",
       "0          1537  1750-03-01        2.773       2.227\n",
       "1          1537  1772-04-01        9.009       2.700\n",
       "2          1537  1797-03-01        2.155       1.986\n",
       "3          1537  1814-06-01       19.209       1.843\n",
       "4          1537  1820-01-01       -5.747       8.125"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_fct.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "write_to_s3(temp_fct, 'temp_fct', partitionBy=['TEMP_CITY_ID', 'MSR_DT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3.3 Temperature dataframe dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_dict_temp = {\n",
    "    'TEMP_FCT': temp_fct.toPandas(),\n",
    "    'TEMP_DIM_CITY': temp_dim_city.toPandas()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.4 Immigration data\n",
    "This data set comprises the main data set for the data model. We will split this data set into four tables:\n",
    "\n",
    "1. IMM_FCT - this provides all the facts for each immigration case\n",
    "2. IMM_DIM_PSN - this explains the immigrant data points for each immigration case\n",
    "3. IMM_DIM_ARPT - this explains all airport and flight information regarding each immigration case\n",
    "4. IMM_DIM_VISA - this explains the immigrant's visa situation in each immigration case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imm_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>None</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20130811</td>\n",
       "      <td>SEO</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN    None   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa entdepd  \\\n",
       "0      NaN    37.0      2.0    1.0      None     None  None       T    None   \n",
       "1      NaN    25.0      3.0    1.0  20130811      SEO  None       G    None   \n",
       "2  20691.0    55.0      2.0    1.0  20160401     None  None       T       O   \n",
       "3  20567.0    28.0      2.0    1.0  20160401     None  None       O       O   \n",
       "4  20567.0     4.0      2.0    1.0  20160401     None  None       O       O   \n",
       "\n",
       "  entdepu matflag  biryear   dtaddto gender insnum airline        admnum  \\\n",
       "0       U    None   1979.0  10282016   None   None    None  1.897628e+09   \n",
       "1       Y    None   1991.0       D/S      M   None    None  3.736796e+09   \n",
       "2    None       M   1961.0  09302016      M   None      OS  6.666432e+08   \n",
       "3    None       M   1988.0  09302016   None   None      AA  9.246846e+10   \n",
       "4    None       M   2012.0  09302016   None   None      AA  9.246846e+10   \n",
       "\n",
       "   fltno visatype  \n",
       "0   None       B2  \n",
       "1  00296       F1  \n",
       "2     93       B2  \n",
       "3  00199       B2  \n",
       "4  00199       B2  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imm_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.4.1 Fact\n",
    "\n",
    "Although most codes will be explained in a separate code-table, we have a specific field that needs to be adjusted slightly.\n",
    "\n",
    "- **dtaddto**\n",
    "\n",
    "Date until end of stay which is typically an eight character date ('MMddyyyy') has a value, 'D/S', which means duration of stay. To ensure it doesn't become a NULL-value, we translate this value to '12312999' saying that the end date is open-ended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_fct = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT \n",
    "        CAST(rd.cicid AS INTEGER) AS IMM_ID,\n",
    "        \n",
    "        CAST(entdepa  AS CHAR(1)) AS ADM_CD,\n",
    "        CAST(i94mode  AS INTEGER) AS ADM_MTD_CD,\n",
    "        CAST(admnum   AS INTEGER)  AS ADM_NO,\n",
    "        CASE WHEN COALESCE(dtaddto, 'None') = 'None' THEN Date('1900-01-01') when (dtaddto) = 'D/S' then Date('2999-12-31') ELSE to_date(`dtaddto`, 'MMddyyyy') END ADM_TO_DT,\n",
    "        CAST(entdepd  AS CHAR(1)) AS DEP_CD,\n",
    "        CASE WHEN COALESCE(depdate, 'None') = 'None' THEN Date'1900-01-01' ELSE date_add('1960-01-01', `depdate`) END AS DEP_DT,\n",
    "        CAST(entdepu  AS CHAR(1)) AS ADM_UPD_CD\n",
    "        \n",
    "    FROM immi_raw AS rd\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMM_ID</th>\n",
       "      <th>ADM_CD</th>\n",
       "      <th>ADM_MTD_CD</th>\n",
       "      <th>ADM_NO</th>\n",
       "      <th>ADM_TO_DT</th>\n",
       "      <th>DEP_CD</th>\n",
       "      <th>DEP_DT</th>\n",
       "      <th>ADM_UPD_CD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>2147483647</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>O</td>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>2147483647</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>R</td>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>414</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>2147483647</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>O</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>2147483647</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>O</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>584</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>2147483647</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>O</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IMM_ID ADM_CD  ADM_MTD_CD      ADM_NO   ADM_TO_DT DEP_CD      DEP_DT  \\\n",
       "0      93      G           1  2147483647  2016-06-29      O  2016-04-09   \n",
       "1     166      G           1  2147483647  2016-06-29      R  2016-04-09   \n",
       "2     414      G           1  2147483647  2016-06-29      O  2016-04-22   \n",
       "3     550      G           1  2147483647  2016-06-29      O  2016-04-30   \n",
       "4     584      G           1  2147483647  2016-06-29      O  2016-04-08   \n",
       "\n",
       "  ADM_UPD_CD  \n",
       "0       None  \n",
       "1       None  \n",
       "2       None  \n",
       "3       None  \n",
       "4       None  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imm_fct.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "write_to_s3(imm_fct, 'imm_fct', partitionBy=['ADM_MTD_CD', 'ADM_CD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.4.2 DIM PSN table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_dim_psn = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT \n",
    "        CAST(rd.cicid AS INTEGER)                                                            AS IMM_ID ,\n",
    "        CASE WHEN COALESCE(insnum, 'None') = 'None' THEN -1 ELSE CAST(insnum AS INTEGER) END AS INS_ID  ,\n",
    "        CAST(biryear AS INTEGER)                                                             AS BRTH_YR ,\n",
    "        CAST(i94bir AS INTEGER)                                                              AS AGE     ,\n",
    "        CASE WHEN COALESCE(occup, 'None') = 'None' THEN 'XXX' ELSE occup END                 AS OCC_CD  ,\n",
    "        CASE WHEN COALESCE(gender, 'None') = 'None' THEN 'U' ELSE gender END                 AS GNDR_CD ,\n",
    "        CAST(rd.i94cit AS INTEGER)                                                           AS CTY_OF_CTZ_ID ,\n",
    "        CAST(rd.i94res AS INTEGER)                                                           AS CTY_OF_RSDN_ID ,\n",
    "        CASE WHEN COALESCE(i94addr, 'None') = 'None' THEN 'XX' ELSE i94addr END              AS ADR_RGN_CD\n",
    "    FROM immi_raw AS rd\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMM_ID</th>\n",
       "      <th>INS_ID</th>\n",
       "      <th>BRTH_YR</th>\n",
       "      <th>AGE</th>\n",
       "      <th>OCC_CD</th>\n",
       "      <th>GNDR_CD</th>\n",
       "      <th>CTY_OF_CTZ_ID</th>\n",
       "      <th>CTY_OF_RSDN_ID</th>\n",
       "      <th>ADR_RGN_CD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127</td>\n",
       "      <td>-1</td>\n",
       "      <td>1991</td>\n",
       "      <td>25</td>\n",
       "      <td>XXX</td>\n",
       "      <td>F</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137</td>\n",
       "      <td>-1</td>\n",
       "      <td>2000</td>\n",
       "      <td>16</td>\n",
       "      <td>XXX</td>\n",
       "      <td>F</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>460</td>\n",
       "      <td>-1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>XXX</td>\n",
       "      <td>U</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>527</td>\n",
       "      <td>-1</td>\n",
       "      <td>1985</td>\n",
       "      <td>31</td>\n",
       "      <td>XXX</td>\n",
       "      <td>M</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1250</td>\n",
       "      <td>-1</td>\n",
       "      <td>1988</td>\n",
       "      <td>28</td>\n",
       "      <td>XXX</td>\n",
       "      <td>M</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IMM_ID  INS_ID  BRTH_YR  AGE OCC_CD GNDR_CD  CTY_OF_CTZ_ID  CTY_OF_RSDN_ID  \\\n",
       "0     127      -1     1991   25    XXX       F            103             103   \n",
       "1     137      -1     2000   16    XXX       F            103             103   \n",
       "2     460      -1     2013    3    XXX       U            103             103   \n",
       "3     527      -1     1985   31    XXX       M            103             103   \n",
       "4    1250      -1     1988   28    XXX       M            104             104   \n",
       "\n",
       "  ADR_RGN_CD  \n",
       "0         NJ  \n",
       "1         NY  \n",
       "2         FL  \n",
       "3         NV  \n",
       "4         NY  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imm_dim_psn.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "write_to_s3(imm_dim_psn, 'imm_dim_psn', partitionBy=['ADR_RGN_CD', 'BRTH_YR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.4.3 DIM ARPT TBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_dim_arpt = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT \n",
    "        CAST(cicid AS INTEGER)       AS IMM_ID,\n",
    "        CAST(i94port AS CHAR(3))     AS ARPT_CD,\n",
    "        CAST(airline AS CHAR(2))     AS ARLN_CD,\n",
    "        CAST(fltno AS CHAR(5))       AS FLGT_CD,\n",
    "        CASE WHEN COALESCE(arrdate, 'None') = 'None' THEN Date'1900-01-01' ELSE date_add('1960-01-01', `arrdate`) END AS ARR_DT\n",
    "    FROM immi_raw AS rd\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_dim_arpt.createOrReplaceTempView('arpt_dim_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMM_ID</th>\n",
       "      <th>ARPT_CD</th>\n",
       "      <th>ARLN_CD</th>\n",
       "      <th>FLGT_CD</th>\n",
       "      <th>ARR_DT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>ATL</td>\n",
       "      <td>OS</td>\n",
       "      <td>00089</td>\n",
       "      <td>2016-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DL</td>\n",
       "      <td>00131</td>\n",
       "      <td>2016-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>246</td>\n",
       "      <td>NYC</td>\n",
       "      <td>AA</td>\n",
       "      <td>00065</td>\n",
       "      <td>2016-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>417</td>\n",
       "      <td>MIA</td>\n",
       "      <td>OS</td>\n",
       "      <td>00097</td>\n",
       "      <td>2016-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>686</td>\n",
       "      <td>MIA</td>\n",
       "      <td>OS</td>\n",
       "      <td>00097</td>\n",
       "      <td>2016-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IMM_ID ARPT_CD ARLN_CD FLGT_CD      ARR_DT\n",
       "0      30     ATL      OS   00089  2016-04-01\n",
       "1      69     ATL      DL   00131  2016-04-01\n",
       "2     246     NYC      AA   00065  2016-04-01\n",
       "3     417     MIA      OS   00097  2016-04-01\n",
       "4     686     MIA      OS   00097  2016-04-01"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imm_dim_arpt.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.4.4 DIM VISA TBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_dim_visa = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT\n",
    "        CAST(rd.cicid AS INTEGER) AS IMM_ID,\n",
    "        CAST(visatype AS CHAR(2)) AS VISA_TP_CD,\n",
    "        CAST(i94visa AS INTEGER)  AS VISA_RSN_CD,\n",
    "        CAST(visapost AS CHAR(3)) AS VISA_ISSU_DEP_CD\n",
    "    FROM immi_raw AS rd        \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_dim_visa.createOrReplaceTempView('visa_dim_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMM_ID</th>\n",
       "      <th>VISA_TP_CD</th>\n",
       "      <th>VISA_RSN_CD</th>\n",
       "      <th>VISA_ISSU_DEP_CD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>265</td>\n",
       "      <td>WT</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>702</td>\n",
       "      <td>WT</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>733</td>\n",
       "      <td>WT</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>765</td>\n",
       "      <td>WT</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>888</td>\n",
       "      <td>WT</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IMM_ID VISA_TP_CD  VISA_RSN_CD VISA_ISSU_DEP_CD\n",
       "0     265         WT            2             None\n",
       "1     702         WT            2             None\n",
       "2     733         WT            2             None\n",
       "3     765         WT            2             None\n",
       "4     888         WT            2             None"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imm_dim_visa.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.4.5 Immigration dataframe dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_dict_imm = {\n",
    "    'IMM_FCT': imm_fct.toPandas(),\n",
    "    'IMM_DIM_PSN': imm_dim_psn.toPandas(),\n",
    "    'IMM_DIM_ARPT': imm_dim_arpt.toPandas(),\n",
    "    'IMM_DIM_VISA': imm_dim_visa.toPandas()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 5. Creating the data dictionaries\n",
    "\n",
    "Documentation of all objects in this project will be done through data dictionaries. The format will be the following:\n",
    "1. Table name\n",
    "2. Data type\n",
    "3. Field size\n",
    "4. Field description\n",
    "5. Example\n",
    "\n",
    "The dictionaries will be created for each table then be combined for one large dictionary. The order of creation will be as follows:\n",
    "0. Code tables built from text files and Google searches\n",
    "1. Airport data\n",
    "2. Demograhics data\n",
    "3. Temperature data\n",
    "4. Immigration data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 5.0 Data from text files and Google\n",
    "Here the sas description file tables are being documented together with departure codes found by way of Google."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.0.1 Airport codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "arpt_cd_dict = {\n",
    "    'Table': 'CD_ARPT',\n",
    "    'Field Name': [\n",
    "        'ARPT_CD',\n",
    "        'ARPT_NM',\n",
    "        'ARPT_STT_CD'\n",
    "    ],\n",
    "    'Data Type': [\n",
    "        'CHAR(3)',\n",
    "        'VARCHAR(100)',\n",
    "        'CHAR(2)'\n",
    "    ],\n",
    "    'Field size for display': [\n",
    "        '3',\n",
    "        '38',\n",
    "        '2'\n",
    "    ],\n",
    "    'Description': [\n",
    "        'Airport CD consisting of 3 letters',\n",
    "        'Airport name (typically the name of the city). Can be \"Collapsed\" or No Port Code or otherwise unkown.',\n",
    "        '2-letter code for the state the airport is in'\n",
    "    ],\n",
    "    'Example': [\n",
    "        'ANC',\n",
    "        'ANCHORAGE',\n",
    "        'AK'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "arpt_cd_dict_df = pd.DataFrame.from_dict(arpt_cd_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.0.2 Region codes (states and other territories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "rgn_cd_dict = {\n",
    "    'Table': 'CD_RGN',\n",
    "    'Field Name': [\n",
    "        'RGN_CD',\n",
    "        'RGN_NM'\n",
    "    ],\n",
    "    'Data Type': [\n",
    "        'CHAR(2)',\n",
    "        'VARCHAR(100)'\n",
    "    ],\n",
    "    'Field size for display': [\n",
    "        '2',\n",
    "        '17'\n",
    "    ],\n",
    "    'Description': [\n",
    "        'Code for US state or region',\n",
    "        'Name of US State or region'\n",
    "    ],\n",
    "    'Example': [\n",
    "        'AK',\n",
    "        'ALASKA'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "rgn_cd_dict_df = pd.DataFrame.from_dict(rgn_cd_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.0.3 Country codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cty_cd_dict = {\n",
    "    'Table': 'CD_CTY',\n",
    "    'Field Name': [\n",
    "        'CTY_CD',\n",
    "        'CTY_NM'\n",
    "    ],\n",
    "    'Data Type': [\n",
    "        'INTEGER',\n",
    "        'VARCHAR(100)'\n",
    "    ],\n",
    "    'Field size for display': [\n",
    "        '3',\n",
    "        '57'\n",
    "    ],\n",
    "    'Description': [\n",
    "        'Country code consisting of up to 3 integers',\n",
    "        'Country name'\n",
    "    ],\n",
    "    'Example': [\n",
    "        '236',\n",
    "        'AFGHANISTAN'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cty_cd_dict_df = pd.DataFrame.from_dict(cty_cd_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.0.4 Admission method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "adm_mtd_cd_dict = {\n",
    "    'Table': 'CD_ADM_MTD',\n",
    "    'Field Name': [\n",
    "        'ADM_MTD_CD',\n",
    "        'ADM_MTD_NM'\n",
    "    ],\n",
    "    'Data Type': [\n",
    "        'INTEGER',\n",
    "        'VARCHAR(100)'\n",
    "    ],\n",
    "    'Field size for display': [\n",
    "        '3',\n",
    "        '12'\n",
    "    ],\n",
    "    'Description': [\n",
    "        'Method code taking on 1, 2, 3, or 9',\n",
    "        'Description of whether immigrant came by Air, Sea, Land or Not reported'\n",
    "    ],\n",
    "    'Example': [\n",
    "        '3',\n",
    "        'Land'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "adm_mtd_cd_dict_df = pd.DataFrame.from_dict(adm_mtd_cd_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.0.5 Visa codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "visa_cd_dict = {\n",
    "    'Table': 'CD_VISA',\n",
    "    'Field Name': [\n",
    "        'VISA_CD',\n",
    "        'VISA_NM'\n",
    "    ],\n",
    "    'Data Type': [\n",
    "        'INTEGER',\n",
    "        'VARCHAR(100)'\n",
    "    ],\n",
    "    'Field size for display': [\n",
    "        '1',\n",
    "        '8'\n",
    "    ],\n",
    "    'Description': [\n",
    "        'Code for reason for applying for a visa',\n",
    "        'Description for reason for applying for a visa'\n",
    "    ],\n",
    "    'Example': [\n",
    "        '1',\n",
    "        'Business'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "visa_cd_dict_df = pd.DataFrame.from_dict(visa_cd_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.0.6 Admission status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "adm_st_cd_dict = {\n",
    "    'Table': 'CD_ADM_ST',\n",
    "    'Field Name': [\n",
    "        'ADM_ST_CD',\n",
    "        'ADM_ST_NM'\n",
    "    ],\n",
    "    'Data Type': [\n",
    "        'CHAR(1)',\n",
    "        'VARCHAR(100)'\n",
    "    ],\n",
    "    'Field size for display': [\n",
    "        '1',\n",
    "        '23'\n",
    "    ],\n",
    "    'Description': [\n",
    "        'Code for admission status',\n",
    "        'Description for admission status'\n",
    "    ],\n",
    "    'Example': [\n",
    "        'G',\n",
    "        'Admitted into US'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "adm_st_cd_dict_df = pd.DataFrame.from_dict(adm_st_cd_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.0.7 Departure codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dep_st_cd_dict = {\n",
    "    'Table': 'CD_DEP',\n",
    "    'Field Name': [\n",
    "        'DEP_CD',\n",
    "        'DEP_NM'\n",
    "    ],\n",
    "    'Data Type': [\n",
    "        'CHAR(1)',\n",
    "        'VARCHAR(150)'\n",
    "    ],\n",
    "    'Field size for display': [\n",
    "        '1',\n",
    "        '115'\n",
    "    ],\n",
    "    'Description': [\n",
    "        'Code for departure reason',\n",
    "        'Description for departure reason - the letter codes match documentation, but the description seems odd.'\n",
    "    ],\n",
    "    'Example': [\n",
    "        'D',\n",
    "        'Alien crewman'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dep_st_cd_dict_df = pd.DataFrame.from_dict(dep_st_cd_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.0.8 Combine all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cd_dict_df = arpt_cd_dict_df \\\n",
    "  .append(rgn_cd_dict_df) \\\n",
    "  .append(cty_cd_dict_df) \\\n",
    "  .append(adm_mtd_cd_dict_df) \\\n",
    "  .append(visa_cd_dict_df) \\\n",
    "  .append(adm_st_cd_dict_df) \\\n",
    "  .append(dep_st_cd_dict_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 5.1 Airport tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.1.1 Airport dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "arpt_dict = {\n",
    "    'Table': 'ARPT_FCT',\n",
    "    'Field Name': [\n",
    "        'ARPT_ID',     \n",
    "        'ARPT_TP',     \n",
    "        'ARPT_NM',     \n",
    "        'ELEV_FT',     \n",
    "        'CONT_CD',     \n",
    "        'ISO_CTY_CD',  \n",
    "        'ISO_RGN_CD',  \n",
    "        'MUNI_NM',     \n",
    "        'GPS_CD',      \n",
    "        'IATA_ARPT_CD',\n",
    "        'LCL_ARPT_CD', \n",
    "        'LAT_VAL',     \n",
    "        'LONG_VAL' \n",
    "    ],\n",
    "    'Data Type': [\n",
    "        'CHAR(4)',\n",
    "        'VARCHAR(20)',\n",
    "        'VARCHAR(255)',\n",
    "        'DECIMAL(9,2)',\n",
    "        'CHAR(2)',\n",
    "        'CHAR(2)',\n",
    "        'CHAR(7)',\n",
    "        'VARCHAR(255)',\n",
    "        'CHAR(4)',\n",
    "        'CHAR(3)',\n",
    "        'CHAR(3)',\n",
    "        'DECIMAL(4,2)',\n",
    "        'DECIMAL(5,2)'\n",
    "    ],\n",
    "    'Field size for display': [\n",
    "        '4',\n",
    "        '20',\n",
    "        '255',\n",
    "        '9',\n",
    "        '2',\n",
    "        '2',\n",
    "        '7',\n",
    "        '255',\n",
    "        '4',\n",
    "        '3',\n",
    "        '3',\n",
    "        '4',\n",
    "        '5'\n",
    "    ],\n",
    "    'Description': [\n",
    "        'Airport ID consisting of letters and numbers',\n",
    "        'Type of airport, including \"Closed\" in case it is so.',\n",
    "        'Name of airport',\n",
    "        'Elevation of airport above sea level in feet',\n",
    "        '2-letter code of continent, e.g. NA for North America',\n",
    "        'ISO Country code, 2 characters',\n",
    "        '4-letter code of region in format \"country - State\" although state may also be just a region',\n",
    "        'Name of municipality',\n",
    "        'GPS location code - see also ARPT_ID',\n",
    "        'IATA airport code, similar to ARPT_ID and GPS_CD',\n",
    "        'Local airport code, similar to ARPT_ID, GPS_CD, IATA_ARPT_CD',\n",
    "        'Latitude',\n",
    "        'Longitude'\n",
    "    ],\n",
    "    'Example': [\n",
    "        '00TS',\n",
    "        'Small Airport',\n",
    "        'Alpine Range Airport',\n",
    "        '670.00',\n",
    "        'NA',\n",
    "        'US',\n",
    "        'US-TX',\n",
    "        'Everman',\n",
    "        '00TS',\n",
    "        '00TS',\n",
    "        '00TS',\n",
    "        '32.61',\n",
    "        '-97.24'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "arpt_dict_df = pd.DataFrame.from_dict(arpt_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 5.2 Demographics data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.2.1 Demographics main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demo_fct_dict = {\n",
    "    'Table': 'DEMO_FCT',\n",
    "    'Field Name': [\n",
    "        'DEMO_CITY_ID',\n",
    "        'RGN_CD',\n",
    "        'RGN_NM',     \n",
    "        'CITY_NM',    \n",
    "        'MED_AGE',    \n",
    "        'POP_TOT_AMT',\n",
    "        'POP_MLE_AMT',\n",
    "        'POP_FMLE_AMT',\n",
    "        'POP_VET_AMT',\n",
    "        'POP_FGN_AMT',\n",
    "        'AVG_HH_SZ'\n",
    "    ],\n",
    "    'Data Type': [\n",
    "        'INTEGER',\n",
    "        'CHAR(2)',\n",
    "        'VARCHAR(255)',\n",
    "        'VARCHAR(255)', \n",
    "        'DECIMAL(4,1)',\n",
    "        'INTEGER',\n",
    "        'INTEGER',     \n",
    "        'INTEGER',     \n",
    "        'INTEGER',     \n",
    "        'INTEGER',     \n",
    "        'DECIMAL(4,2)' \n",
    "    ],\n",
    "    'Field size for display': [\n",
    "        '4',\n",
    "        '2',\n",
    "        '255',\n",
    "        '255', \n",
    "        '4',\n",
    "        '8',\n",
    "        '8',     \n",
    "        '8',     \n",
    "        '8',     \n",
    "        '8',     \n",
    "        '4'\n",
    "    ],\n",
    "    'Description': [\n",
    "        'Identification (serial) number of city',\n",
    "        '2-letter code for region - typically a US state',\n",
    "        'Name for region - typically a US state',\n",
    "        'Name of city',\n",
    "        'Median age in city',\n",
    "        'Total population in city',\n",
    "        'Total male population in city',\n",
    "        'Total female population in city',\n",
    "        'Total veteran population in city',\n",
    "        'Total foreign-born population in city',\n",
    "        'Average size of household in city'\n",
    "    ],\n",
    "    'Example': [\n",
    "        '1',\n",
    "        'MO',\n",
    "        'Missouri',\n",
    "        'Independence',\n",
    "        '38.6',\n",
    "        '117255',\n",
    "        '54348',\n",
    "        '62907',\n",
    "        '10220',\n",
    "        '4911',\n",
    "        '2.33'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demo_fct_dict_df = pd.DataFrame.from_dict(demo_fct_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.2.2 Race population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demo_fct_race_dict = {\n",
    "    'Table': 'DEMO_FCT_RACE',\n",
    "    'Field Name': [\n",
    "        'DEMO_CITY_ID',\n",
    "        'RACE_TP_CD',\n",
    "        'POP_RACE_AMT'\n",
    "    ],\n",
    "    'Data Type': [\n",
    "        'INTEGER',\n",
    "        'CHAR(4)',\n",
    "        'INTEGER'\n",
    "    ],\n",
    "    'Field size for display': [\n",
    "        '4',\n",
    "        '4',\n",
    "        '8'\n",
    "    ],\n",
    "    'Description': [\n",
    "        'City ID, same as for DEMO_FCT table',\n",
    "        '4-letter code for race',\n",
    "        'Total population of specific race for specific city'\n",
    "    ],\n",
    "    'Example': [\n",
    "        '447',\n",
    "        'BLAA',\n",
    "        '138242'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demo_fct_race_dict_df = pd.DataFrame.from_dict(demo_fct_race_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.2.3 Race codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "race_tp_cd_dict = {\n",
    "    'Table': 'CD_RACE_TP',\n",
    "    'Field Name': [\n",
    "        'RACE_TP_CD',\n",
    "        'POP_RACE_AMT'\n",
    "    ],\n",
    "    'Data Type': [\n",
    "        'CHAR(4)',\n",
    "        'VARCHAR(50)'\n",
    "    ],\n",
    "    'Field size for display': [\n",
    "        '4',\n",
    "        '255'\n",
    "    ],\n",
    "    'Description': [\n",
    "        '4-letter code for race',\n",
    "        'Race relating to the race code'\n",
    "    ],\n",
    "    'Example': [\n",
    "        'AIAN',\n",
    "        'American Indian and Alaska Native'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "race_tp_cd_dict_df = pd.DataFrame.from_dict(race_tp_cd_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.2.4 Combine all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demo_dict_df = demo_fct_dict_df \\\n",
    "  .append(demo_fct_race_dict_df) \\\n",
    "  .append(race_tp_cd_dict_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 5.3 Temperature data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.3.1 TEMP_CITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_city_dict = {\n",
    "    'Table': 'TEMP_DIM_CITY',\n",
    "    'Field Name': [\n",
    "        'TEMP_CITY_ID',\n",
    "        'CITY_NM',\n",
    "        'CTY_NM',\n",
    "        'LAT_VAL',\n",
    "        'LONG_VAL'\n",
    "    ],\n",
    "    'Data Type': [\n",
    "        'INTEGER',\n",
    "        \"VARCHAR(255)\",\n",
    "        'VARCHAR(255)',\n",
    "        'DECIMAL(4,2)',\n",
    "        'DECIMAL(5,3)'\n",
    "    ],\n",
    "    'Field size for display': [\n",
    "        '4',\n",
    "        '255',\n",
    "        '255',\n",
    "        '4',\n",
    "        '5'\n",
    "    ],\n",
    "    'Description': [\n",
    "        'Id for city in temperature data set (serial id)',\n",
    "        'Name of city',\n",
    "        'Name of country',\n",
    "        'Latitude',\n",
    "        'Longitude'\n",
    "    ],\n",
    "    'Example': [\n",
    "        '1',\n",
    "        'Ontario',\n",
    "        'United States',\n",
    "        '34.56',\n",
    "        '-116.76'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_city_dict_df = pd.DataFrame.from_dict(temp_city_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.3.2 TEMP FCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_fct_dict = {\n",
    "    'Table': 'TEMP_FCT',\n",
    "    'Field Name': [\n",
    "        'TEMP_CITY_ID',\n",
    "        'MSR_DT',\n",
    "        'TEMP_AVG_VAL',\n",
    "        'TEMP_SD_VAL'\n",
    "    ],\n",
    "    'Data Type': [\n",
    "        'INTEGER',\n",
    "        \"DATE 'YYYY-MM-DD'\",\n",
    "        'DECIMAL(5,3)',\n",
    "        'DECIMAL(5,3)'\n",
    "    ],\n",
    "    'Field size for display': [\n",
    "        '4',\n",
    "        '10',\n",
    "        '5',\n",
    "        '5'\n",
    "    ],\n",
    "    'Description': [\n",
    "        'Id for city in temperature data set (serial id)',\n",
    "        'Date of temperature measuremenet',\n",
    "        'Average temperature for date for city',\n",
    "        'Average temperature uncertainty (standard deviation) for city'\n",
    "    ],\n",
    "    'Example': [\n",
    "        '1537',\n",
    "        '1750-03-01',\n",
    "        '2.773',\n",
    "        '2.227'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_fct_dict_df = pd.DataFrame.from_dict(temp_fct_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_dict_df = temp_city_dict_df \\\n",
    "  .append(temp_fct_dict_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 5.4 Immigration data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.4.1 Fct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_fct_dict = {\n",
    "    'Table': 'IMM_FCT',\n",
    "    'Field Name': [\n",
    "        'IMM_ID',\n",
    "        'ADM_CD',\n",
    "        'ADM_MTD_CD',     \n",
    "        'ADM_NO',    \n",
    "        'ADM_TO_DT',    \n",
    "        'DEP_CD',\n",
    "        'DEP_DT',\n",
    "        'ADM_UPD_CD'\n",
    "    ],\n",
    "    'Data Type': [\n",
    "        'INTEGER',\n",
    "        'CHAR(1)',\n",
    "        'INTEGER',\n",
    "        'INTEGER',  \n",
    "        \"DATE 'YYYY-MM-DD'\",\n",
    "        'CHAR(1)',     \n",
    "        \"DATE 'YYYY-MM-DD'\",\n",
    "        'CHAR(1)'\n",
    "    ],\n",
    "    'Field size for display': [\n",
    "        '4',\n",
    "        '1',\n",
    "        '1',\n",
    "        '10', \n",
    "        '10',\n",
    "        '1',\n",
    "        '10',\n",
    "        '1'\n",
    "    ],\n",
    "    'Description': [\n",
    "        'Immigration case ID',\n",
    "        '1-letter code explaining the cause of admission into the US',\n",
    "        '1-letter code explaining the entry into the US',\n",
    "        'An admission number which is technical only',\n",
    "        'End date until when the admitted person can stay in the US. Defaults to 1900-01-01 when there is no date, and 2999-12-31 when the visa is granted for duration of stay',\n",
    "        'Reason for departure',\n",
    "        'Date of departure',\n",
    "        'Code for admission updates'\n",
    "    ],\n",
    "    'Example': [\n",
    "        '93',\n",
    "        'G',\n",
    "        '1',\n",
    "        '2147483647',\n",
    "        '2016-06-29',\n",
    "        'O',\n",
    "        '2016-04-09',\n",
    "        'None'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_fct_dict_df = pd.DataFrame.from_dict(imm_fct_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.4.2 Person dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_psn_dict = {\n",
    "    'Table': 'IMM_DIM_PSN',\n",
    "    'Field Name': [\n",
    "        'IMM_ID',\n",
    "        'INS_ID',\n",
    "        'BRTH_YR',     \n",
    "        'AGE',    \n",
    "        'OCC_CD',    \n",
    "        'GNDR_CD',\n",
    "        'CTY_OF_RSDN_ID',\n",
    "        'CTY_OF_CTZ_ID',\n",
    "        'ADR_RGN_CD'\n",
    "    ],\n",
    "    'Data Type': [\n",
    "        'INTEGER',\n",
    "        'INTEGER',\n",
    "        'INTEGER',\n",
    "        'INTEGER',  \n",
    "        \"CHAR(3)\",\n",
    "        'CHAR(1)',     \n",
    "        \"INTEGER\",\n",
    "        'INTEGER', \n",
    "        \"CHAR(2)\"\n",
    "    ],\n",
    "    'Field size for display': [\n",
    "        '4',\n",
    "        '6',\n",
    "        '4',\n",
    "        '3', \n",
    "        '3',\n",
    "        '1',\n",
    "        '3',\n",
    "        '3',\n",
    "        '2'\n",
    "    ],\n",
    "    'Description': [\n",
    "        'Immigration case ID',\n",
    "        'Insurance ID, takes on -1 in the event it is undefined',\n",
    "        'Year of birth',\n",
    "        'Age in years',\n",
    "        'Three letter code for occupation - not decoded in this data model',\n",
    "        'One-letter code for (M)ale, (F)emale or (U)nknown',\n",
    "        'ID of country of prior citizenship',\n",
    "        'ID of country of prior residence',\n",
    "        'State code of immigrants new address',\n",
    "        \n",
    "    ],\n",
    "    'Example': [\n",
    "        '127',\n",
    "        '545507',\n",
    "        '1991',\n",
    "        '25',\n",
    "        'XXX',\n",
    "        'F',\n",
    "        '103',\n",
    "        '103',\n",
    "        'NJ'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_psn_dict_df = pd.DataFrame.from_dict(imm_psn_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.4.3 Airport dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_arpt_dict = {\n",
    "    'Table': 'IMM_DIM_ARPT',\n",
    "    'Field Name': [\n",
    "        'IMM_ID',\n",
    "        'ARPT_CD',\n",
    "        'ARLN_CD',     \n",
    "        'FLGT_CD',    \n",
    "        'ARR_DT'\n",
    "    ],\n",
    "    'Data Type': [\n",
    "        'INTEGER',  \n",
    "        \"CHAR(3)\",\n",
    "        'CHAR(2)',     \n",
    "        \"CHAR(5)\",\n",
    "        \"DATE 'YYYY-MM-DD'\"\n",
    "    ],\n",
    "    'Field size for display': [\n",
    "        '4',\n",
    "        '3',\n",
    "        '2',\n",
    "        '5', \n",
    "        '10'\n",
    "    ],\n",
    "    'Description': [\n",
    "        'Immigration case ID',\n",
    "        '3-letter code for airport city of arrival flight to the US',\n",
    "        '2-letter code for airline of arrival flight to the US',\n",
    "        '5 character code for flight number of arrival flight to the US',\n",
    "        'Date of arrival in the US, not admission'\n",
    "    ],\n",
    "    'Example': [\n",
    "        '30',\n",
    "        'ATL',\n",
    "        'OS',\n",
    "        '00089',\n",
    "        '2016-04-01'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_arpt_dict_df = pd.DataFrame.from_dict(imm_arpt_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.4.4 Visa dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_visa_dict = {\n",
    "    'Table': 'IMM_DIM_VISA',\n",
    "    'Field Name': [\n",
    "        'IMM_ID',\n",
    "        'VISA_TP_CD',\n",
    "        'VISA_RSN_CD',     \n",
    "        'VISA_ISSU_DEP_CD'\n",
    "    ],\n",
    "    'Data Type': [\n",
    "        'INTEGER',  \n",
    "        \"CHAR(2)\",\n",
    "        'INTEGER',     \n",
    "        \"CHAR(3)\"\n",
    "    ],\n",
    "    'Field size for display': [\n",
    "        '4',\n",
    "        '2',\n",
    "        '1',\n",
    "        '3'\n",
    "    ],\n",
    "    'Description': [\n",
    "        'Immigration case ID',\n",
    "        '2-letter code for VISA obtained - not decoded',\n",
    "        '1 digit code for VISA application reason - decoded in separate table',\n",
    "        '3-letter code for issuing city of VISA'\n",
    "    ],\n",
    "    'Example': [\n",
    "        '265',\n",
    "        'WT',\n",
    "        '2',\n",
    "        'None'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_visa_dict_df = pd.DataFrame.from_dict(imm_visa_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.4.5 Combine all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_dict_df = imm_fct_dict_df \\\n",
    "  .append(imm_psn_dict_df) \\\n",
    "  .append(imm_arpt_dict_df) \\\n",
    "  .append(imm_visa_dict_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 5.5 Combine all\n",
    "Through the above work and the below consolidation all data fields are documented and can be visualised however it pleases the user, be it on a wiki page or exported to an excel-sheet etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_dict_df = cd_dict_df \\\n",
    "  .append(arpt_dict_df, ignore_index = True) \\\n",
    "  .append(demo_dict_df, ignore_index = True) \\\n",
    "  .append(temp_dict_df, ignore_index = True) \\\n",
    "  .append(imm_dict_df, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table</th>\n",
       "      <th>Field Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Field size for display</th>\n",
       "      <th>Description</th>\n",
       "      <th>Example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ARPT_FCT</td>\n",
       "      <td>ISO_CTY_CD</td>\n",
       "      <td>CHAR(2)</td>\n",
       "      <td>2</td>\n",
       "      <td>ISO Country code, 2 characters</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ARPT_FCT</td>\n",
       "      <td>ARPT_NM</td>\n",
       "      <td>VARCHAR(255)</td>\n",
       "      <td>255</td>\n",
       "      <td>Name of airport</td>\n",
       "      <td>Alpine Range Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ARPT_FCT</td>\n",
       "      <td>ELEV_FT</td>\n",
       "      <td>DECIMAL(9,2)</td>\n",
       "      <td>9</td>\n",
       "      <td>Elevation of airport above sea level in feet</td>\n",
       "      <td>670.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ARPT_FCT</td>\n",
       "      <td>CONT_CD</td>\n",
       "      <td>CHAR(2)</td>\n",
       "      <td>2</td>\n",
       "      <td>2-letter code of continent, e.g. NA for North ...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ARPT_FCT</td>\n",
       "      <td>ISO_RGN_CD</td>\n",
       "      <td>CHAR(7)</td>\n",
       "      <td>7</td>\n",
       "      <td>4-letter code of region in format \"country - S...</td>\n",
       "      <td>US-TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ARPT_FCT</td>\n",
       "      <td>ARPT_ID</td>\n",
       "      <td>CHAR(4)</td>\n",
       "      <td>4</td>\n",
       "      <td>Airport ID consisting of letters and numbers</td>\n",
       "      <td>00TS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ARPT_FCT</td>\n",
       "      <td>ARPT_TP</td>\n",
       "      <td>VARCHAR(20)</td>\n",
       "      <td>20</td>\n",
       "      <td>Type of airport, including \"Closed\" in case it...</td>\n",
       "      <td>Small Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ARPT_FCT</td>\n",
       "      <td>GPS_CD</td>\n",
       "      <td>CHAR(4)</td>\n",
       "      <td>4</td>\n",
       "      <td>GPS location code - see also ARPT_ID</td>\n",
       "      <td>00TS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ARPT_FCT</td>\n",
       "      <td>IATA_ARPT_CD</td>\n",
       "      <td>CHAR(3)</td>\n",
       "      <td>3</td>\n",
       "      <td>IATA airport code, similar to ARPT_ID and GPS_CD</td>\n",
       "      <td>00TS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ARPT_FCT</td>\n",
       "      <td>LCL_ARPT_CD</td>\n",
       "      <td>CHAR(3)</td>\n",
       "      <td>3</td>\n",
       "      <td>Local airport code, similar to ARPT_ID, GPS_CD...</td>\n",
       "      <td>00TS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ARPT_FCT</td>\n",
       "      <td>LAT_VAL</td>\n",
       "      <td>DECIMAL(4,2)</td>\n",
       "      <td>4</td>\n",
       "      <td>Latitude</td>\n",
       "      <td>32.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ARPT_FCT</td>\n",
       "      <td>LONG_VAL</td>\n",
       "      <td>DECIMAL(5,2)</td>\n",
       "      <td>5</td>\n",
       "      <td>Longitude</td>\n",
       "      <td>-97.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ARPT_FCT</td>\n",
       "      <td>MUNI_NM</td>\n",
       "      <td>VARCHAR(255)</td>\n",
       "      <td>255</td>\n",
       "      <td>Name of municipality</td>\n",
       "      <td>Everman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CD_ADM_MTD</td>\n",
       "      <td>ADM_MTD_CD</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>3</td>\n",
       "      <td>Method code taking on 1, 2, 3, or 9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CD_ADM_MTD</td>\n",
       "      <td>ADM_MTD_NM</td>\n",
       "      <td>VARCHAR(100)</td>\n",
       "      <td>12</td>\n",
       "      <td>Description of whether immigrant came by Air, ...</td>\n",
       "      <td>Land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CD_ADM_ST</td>\n",
       "      <td>ADM_ST_CD</td>\n",
       "      <td>CHAR(1)</td>\n",
       "      <td>1</td>\n",
       "      <td>Code for admission status</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CD_ADM_ST</td>\n",
       "      <td>ADM_ST_NM</td>\n",
       "      <td>VARCHAR(100)</td>\n",
       "      <td>23</td>\n",
       "      <td>Description for admission status</td>\n",
       "      <td>Admitted into US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CD_ARPT</td>\n",
       "      <td>ARPT_CD</td>\n",
       "      <td>CHAR(3)</td>\n",
       "      <td>3</td>\n",
       "      <td>Airport CD consisting of 3 letters</td>\n",
       "      <td>ANC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CD_ARPT</td>\n",
       "      <td>ARPT_NM</td>\n",
       "      <td>VARCHAR(100)</td>\n",
       "      <td>38</td>\n",
       "      <td>Airport name (typically the name of the city)....</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CD_ARPT</td>\n",
       "      <td>ARPT_STT_CD</td>\n",
       "      <td>CHAR(2)</td>\n",
       "      <td>2</td>\n",
       "      <td>2-letter code for the state the airport is in</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CD_CTY</td>\n",
       "      <td>CTY_NM</td>\n",
       "      <td>VARCHAR(100)</td>\n",
       "      <td>57</td>\n",
       "      <td>Country name</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CD_CTY</td>\n",
       "      <td>CTY_CD</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>3</td>\n",
       "      <td>Country code consisting of up to 3 integers</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CD_DEP</td>\n",
       "      <td>DEP_CD</td>\n",
       "      <td>CHAR(1)</td>\n",
       "      <td>1</td>\n",
       "      <td>Code for departure reason</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CD_DEP</td>\n",
       "      <td>DEP_NM</td>\n",
       "      <td>VARCHAR(150)</td>\n",
       "      <td>115</td>\n",
       "      <td>Description for departure reason - the letter ...</td>\n",
       "      <td>Alien crewman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>CD_RACE_TP</td>\n",
       "      <td>RACE_TP_CD</td>\n",
       "      <td>CHAR(4)</td>\n",
       "      <td>4</td>\n",
       "      <td>4-letter code for race</td>\n",
       "      <td>AIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>CD_RACE_TP</td>\n",
       "      <td>POP_RACE_AMT</td>\n",
       "      <td>VARCHAR(50)</td>\n",
       "      <td>255</td>\n",
       "      <td>Race relating to the race code</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CD_RGN</td>\n",
       "      <td>RGN_CD</td>\n",
       "      <td>CHAR(2)</td>\n",
       "      <td>2</td>\n",
       "      <td>Code for US state or region</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CD_RGN</td>\n",
       "      <td>RGN_NM</td>\n",
       "      <td>VARCHAR(100)</td>\n",
       "      <td>17</td>\n",
       "      <td>Name of US State or region</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CD_VISA</td>\n",
       "      <td>VISA_CD</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>1</td>\n",
       "      <td>Code for reason for applying for a visa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CD_VISA</td>\n",
       "      <td>VISA_NM</td>\n",
       "      <td>VARCHAR(100)</td>\n",
       "      <td>8</td>\n",
       "      <td>Description for reason for applying for a visa</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DEMO_FCT</td>\n",
       "      <td>DEMO_CITY_ID</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>4</td>\n",
       "      <td>Identification (serial) number of city</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DEMO_FCT</td>\n",
       "      <td>RGN_NM</td>\n",
       "      <td>VARCHAR(255)</td>\n",
       "      <td>255</td>\n",
       "      <td>Name for region - typically a US state</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DEMO_FCT</td>\n",
       "      <td>CITY_NM</td>\n",
       "      <td>VARCHAR(255)</td>\n",
       "      <td>255</td>\n",
       "      <td>Name of city</td>\n",
       "      <td>Independence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DEMO_FCT</td>\n",
       "      <td>MED_AGE</td>\n",
       "      <td>DECIMAL(4,1)</td>\n",
       "      <td>4</td>\n",
       "      <td>Median age in city</td>\n",
       "      <td>38.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>DEMO_FCT</td>\n",
       "      <td>POP_TOT_AMT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>8</td>\n",
       "      <td>Total population in city</td>\n",
       "      <td>117255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>DEMO_FCT</td>\n",
       "      <td>POP_MLE_AMT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>8</td>\n",
       "      <td>Total male population in city</td>\n",
       "      <td>54348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>DEMO_FCT</td>\n",
       "      <td>POP_FMLE_AMT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>8</td>\n",
       "      <td>Total female population in city</td>\n",
       "      <td>62907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>DEMO_FCT</td>\n",
       "      <td>POP_VET_AMT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>8</td>\n",
       "      <td>Total veteran population in city</td>\n",
       "      <td>10220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>DEMO_FCT</td>\n",
       "      <td>POP_FGN_AMT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>8</td>\n",
       "      <td>Total foreign-born population in city</td>\n",
       "      <td>4911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>DEMO_FCT</td>\n",
       "      <td>AVG_HH_SZ</td>\n",
       "      <td>DECIMAL(4,2)</td>\n",
       "      <td>4</td>\n",
       "      <td>Average size of household in city</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DEMO_FCT</td>\n",
       "      <td>RGN_CD</td>\n",
       "      <td>CHAR(2)</td>\n",
       "      <td>2</td>\n",
       "      <td>2-letter code for region - typically a US state</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>DEMO_FCT_RACE</td>\n",
       "      <td>DEMO_CITY_ID</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>4</td>\n",
       "      <td>City ID, same as for DEMO_FCT table</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>DEMO_FCT_RACE</td>\n",
       "      <td>RACE_TP_CD</td>\n",
       "      <td>CHAR(4)</td>\n",
       "      <td>4</td>\n",
       "      <td>4-letter code for race</td>\n",
       "      <td>BLAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>DEMO_FCT_RACE</td>\n",
       "      <td>POP_RACE_AMT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>8</td>\n",
       "      <td>Total population of specific race for specific...</td>\n",
       "      <td>138242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>IMM_DIM_ARPT</td>\n",
       "      <td>ARR_DT</td>\n",
       "      <td>DATE 'YYYY-MM-DD'</td>\n",
       "      <td>10</td>\n",
       "      <td>Date of arrival in the US, not admission</td>\n",
       "      <td>2016-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>IMM_DIM_ARPT</td>\n",
       "      <td>FLGT_CD</td>\n",
       "      <td>CHAR(5)</td>\n",
       "      <td>5</td>\n",
       "      <td>5 character code for flight number of arrival ...</td>\n",
       "      <td>00089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>IMM_DIM_ARPT</td>\n",
       "      <td>ARLN_CD</td>\n",
       "      <td>CHAR(2)</td>\n",
       "      <td>2</td>\n",
       "      <td>2-letter code for airline of arrival flight to...</td>\n",
       "      <td>OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>IMM_DIM_ARPT</td>\n",
       "      <td>ARPT_CD</td>\n",
       "      <td>CHAR(3)</td>\n",
       "      <td>3</td>\n",
       "      <td>3-letter code for airport city of arrival flig...</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>IMM_DIM_ARPT</td>\n",
       "      <td>IMM_ID</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>4</td>\n",
       "      <td>Immigration case ID</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>IMM_DIM_PSN</td>\n",
       "      <td>IMM_ID</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>4</td>\n",
       "      <td>Immigration case ID</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>IMM_DIM_PSN</td>\n",
       "      <td>CTY_OF_CTZ_ID</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>3</td>\n",
       "      <td>ID of country of prior residence</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>IMM_DIM_PSN</td>\n",
       "      <td>CTY_OF_RSDN_ID</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>3</td>\n",
       "      <td>ID of country of prior citizenship</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>IMM_DIM_PSN</td>\n",
       "      <td>GNDR_CD</td>\n",
       "      <td>CHAR(1)</td>\n",
       "      <td>1</td>\n",
       "      <td>One-letter code for (M)ale, (F)emale or (U)nknown</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>IMM_DIM_PSN</td>\n",
       "      <td>OCC_CD</td>\n",
       "      <td>CHAR(3)</td>\n",
       "      <td>3</td>\n",
       "      <td>Three letter code for occupation - not decoded...</td>\n",
       "      <td>XXX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>IMM_DIM_PSN</td>\n",
       "      <td>AGE</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>3</td>\n",
       "      <td>Age in years</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>IMM_DIM_PSN</td>\n",
       "      <td>BRTH_YR</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>4</td>\n",
       "      <td>Year of birth</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>IMM_DIM_PSN</td>\n",
       "      <td>INS_ID</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>6</td>\n",
       "      <td>Insurance ID, takes on -1 in the event it is u...</td>\n",
       "      <td>545507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>IMM_DIM_PSN</td>\n",
       "      <td>ADR_RGN_CD</td>\n",
       "      <td>CHAR(2)</td>\n",
       "      <td>2</td>\n",
       "      <td>State code of immigrants new address</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>IMM_DIM_VISA</td>\n",
       "      <td>IMM_ID</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>4</td>\n",
       "      <td>Immigration case ID</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>IMM_DIM_VISA</td>\n",
       "      <td>VISA_TP_CD</td>\n",
       "      <td>CHAR(2)</td>\n",
       "      <td>2</td>\n",
       "      <td>2-letter code for VISA obtained - not decoded</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>IMM_DIM_VISA</td>\n",
       "      <td>VISA_ISSU_DEP_CD</td>\n",
       "      <td>CHAR(3)</td>\n",
       "      <td>3</td>\n",
       "      <td>3-letter code for issuing city of VISA</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>IMM_DIM_VISA</td>\n",
       "      <td>VISA_RSN_CD</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>1</td>\n",
       "      <td>1 digit code for VISA application reason - dec...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>IMM_FCT</td>\n",
       "      <td>DEP_CD</td>\n",
       "      <td>CHAR(1)</td>\n",
       "      <td>1</td>\n",
       "      <td>Reason for departure</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>IMM_FCT</td>\n",
       "      <td>DEP_DT</td>\n",
       "      <td>DATE 'YYYY-MM-DD'</td>\n",
       "      <td>10</td>\n",
       "      <td>Date of departure</td>\n",
       "      <td>2016-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>IMM_FCT</td>\n",
       "      <td>IMM_ID</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>4</td>\n",
       "      <td>Immigration case ID</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>IMM_FCT</td>\n",
       "      <td>ADM_UPD_CD</td>\n",
       "      <td>CHAR(1)</td>\n",
       "      <td>1</td>\n",
       "      <td>Code for admission updates</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>IMM_FCT</td>\n",
       "      <td>ADM_MTD_CD</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>1</td>\n",
       "      <td>1-letter code explaining the entry into the US</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>IMM_FCT</td>\n",
       "      <td>ADM_NO</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>10</td>\n",
       "      <td>An admission number which is technical only</td>\n",
       "      <td>2147483647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>IMM_FCT</td>\n",
       "      <td>ADM_TO_DT</td>\n",
       "      <td>DATE 'YYYY-MM-DD'</td>\n",
       "      <td>10</td>\n",
       "      <td>End date until when the admitted person can st...</td>\n",
       "      <td>2016-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>IMM_FCT</td>\n",
       "      <td>ADM_CD</td>\n",
       "      <td>CHAR(1)</td>\n",
       "      <td>1</td>\n",
       "      <td>1-letter code explaining the cause of admissio...</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>TEMP_DIM_CITY</td>\n",
       "      <td>LONG_VAL</td>\n",
       "      <td>DECIMAL(5,3)</td>\n",
       "      <td>5</td>\n",
       "      <td>Longitude</td>\n",
       "      <td>-116.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TEMP_DIM_CITY</td>\n",
       "      <td>LAT_VAL</td>\n",
       "      <td>DECIMAL(4,2)</td>\n",
       "      <td>4</td>\n",
       "      <td>Latitude</td>\n",
       "      <td>34.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>TEMP_DIM_CITY</td>\n",
       "      <td>CTY_NM</td>\n",
       "      <td>VARCHAR(255)</td>\n",
       "      <td>255</td>\n",
       "      <td>Name of country</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>TEMP_DIM_CITY</td>\n",
       "      <td>CITY_NM</td>\n",
       "      <td>VARCHAR(255)</td>\n",
       "      <td>255</td>\n",
       "      <td>Name of city</td>\n",
       "      <td>Ontario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>TEMP_DIM_CITY</td>\n",
       "      <td>TEMP_CITY_ID</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>4</td>\n",
       "      <td>Id for city in temperature data set (serial id)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>TEMP_FCT</td>\n",
       "      <td>TEMP_SD_VAL</td>\n",
       "      <td>DECIMAL(5,3)</td>\n",
       "      <td>5</td>\n",
       "      <td>Average temperature uncertainty (standard devi...</td>\n",
       "      <td>2.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>TEMP_FCT</td>\n",
       "      <td>TEMP_AVG_VAL</td>\n",
       "      <td>DECIMAL(5,3)</td>\n",
       "      <td>5</td>\n",
       "      <td>Average temperature for date for city</td>\n",
       "      <td>2.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>TEMP_FCT</td>\n",
       "      <td>TEMP_CITY_ID</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>4</td>\n",
       "      <td>Id for city in temperature data set (serial id)</td>\n",
       "      <td>1537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>TEMP_FCT</td>\n",
       "      <td>MSR_DT</td>\n",
       "      <td>DATE 'YYYY-MM-DD'</td>\n",
       "      <td>10</td>\n",
       "      <td>Date of temperature measuremenet</td>\n",
       "      <td>1750-03-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Table        Field Name          Data Type Field size for display  \\\n",
       "20       ARPT_FCT        ISO_CTY_CD            CHAR(2)                      2   \n",
       "17       ARPT_FCT           ARPT_NM       VARCHAR(255)                    255   \n",
       "18       ARPT_FCT           ELEV_FT       DECIMAL(9,2)                      9   \n",
       "19       ARPT_FCT           CONT_CD            CHAR(2)                      2   \n",
       "21       ARPT_FCT        ISO_RGN_CD            CHAR(7)                      7   \n",
       "15       ARPT_FCT           ARPT_ID            CHAR(4)                      4   \n",
       "16       ARPT_FCT           ARPT_TP        VARCHAR(20)                     20   \n",
       "23       ARPT_FCT            GPS_CD            CHAR(4)                      4   \n",
       "24       ARPT_FCT      IATA_ARPT_CD            CHAR(3)                      3   \n",
       "25       ARPT_FCT       LCL_ARPT_CD            CHAR(3)                      3   \n",
       "26       ARPT_FCT           LAT_VAL       DECIMAL(4,2)                      4   \n",
       "27       ARPT_FCT          LONG_VAL       DECIMAL(5,2)                      5   \n",
       "22       ARPT_FCT           MUNI_NM       VARCHAR(255)                    255   \n",
       "7      CD_ADM_MTD        ADM_MTD_CD            INTEGER                      3   \n",
       "8      CD_ADM_MTD        ADM_MTD_NM       VARCHAR(100)                     12   \n",
       "11      CD_ADM_ST         ADM_ST_CD            CHAR(1)                      1   \n",
       "12      CD_ADM_ST         ADM_ST_NM       VARCHAR(100)                     23   \n",
       "0         CD_ARPT           ARPT_CD            CHAR(3)                      3   \n",
       "1         CD_ARPT           ARPT_NM       VARCHAR(100)                     38   \n",
       "2         CD_ARPT       ARPT_STT_CD            CHAR(2)                      2   \n",
       "6          CD_CTY            CTY_NM       VARCHAR(100)                     57   \n",
       "5          CD_CTY            CTY_CD            INTEGER                      3   \n",
       "13         CD_DEP            DEP_CD            CHAR(1)                      1   \n",
       "14         CD_DEP            DEP_NM       VARCHAR(150)                    115   \n",
       "42     CD_RACE_TP        RACE_TP_CD            CHAR(4)                      4   \n",
       "43     CD_RACE_TP      POP_RACE_AMT        VARCHAR(50)                    255   \n",
       "3          CD_RGN            RGN_CD            CHAR(2)                      2   \n",
       "4          CD_RGN            RGN_NM       VARCHAR(100)                     17   \n",
       "9         CD_VISA           VISA_CD            INTEGER                      1   \n",
       "10        CD_VISA           VISA_NM       VARCHAR(100)                      8   \n",
       "28       DEMO_FCT      DEMO_CITY_ID            INTEGER                      4   \n",
       "30       DEMO_FCT            RGN_NM       VARCHAR(255)                    255   \n",
       "31       DEMO_FCT           CITY_NM       VARCHAR(255)                    255   \n",
       "32       DEMO_FCT           MED_AGE       DECIMAL(4,1)                      4   \n",
       "33       DEMO_FCT       POP_TOT_AMT            INTEGER                      8   \n",
       "34       DEMO_FCT       POP_MLE_AMT            INTEGER                      8   \n",
       "35       DEMO_FCT      POP_FMLE_AMT            INTEGER                      8   \n",
       "36       DEMO_FCT       POP_VET_AMT            INTEGER                      8   \n",
       "37       DEMO_FCT       POP_FGN_AMT            INTEGER                      8   \n",
       "38       DEMO_FCT         AVG_HH_SZ       DECIMAL(4,2)                      4   \n",
       "29       DEMO_FCT            RGN_CD            CHAR(2)                      2   \n",
       "39  DEMO_FCT_RACE      DEMO_CITY_ID            INTEGER                      4   \n",
       "40  DEMO_FCT_RACE        RACE_TP_CD            CHAR(4)                      4   \n",
       "41  DEMO_FCT_RACE      POP_RACE_AMT            INTEGER                      8   \n",
       "74   IMM_DIM_ARPT            ARR_DT  DATE 'YYYY-MM-DD'                     10   \n",
       "73   IMM_DIM_ARPT           FLGT_CD            CHAR(5)                      5   \n",
       "72   IMM_DIM_ARPT           ARLN_CD            CHAR(2)                      2   \n",
       "71   IMM_DIM_ARPT           ARPT_CD            CHAR(3)                      3   \n",
       "70   IMM_DIM_ARPT            IMM_ID            INTEGER                      4   \n",
       "61    IMM_DIM_PSN            IMM_ID            INTEGER                      4   \n",
       "68    IMM_DIM_PSN     CTY_OF_CTZ_ID            INTEGER                      3   \n",
       "67    IMM_DIM_PSN    CTY_OF_RSDN_ID            INTEGER                      3   \n",
       "66    IMM_DIM_PSN           GNDR_CD            CHAR(1)                      1   \n",
       "65    IMM_DIM_PSN            OCC_CD            CHAR(3)                      3   \n",
       "64    IMM_DIM_PSN               AGE            INTEGER                      3   \n",
       "63    IMM_DIM_PSN           BRTH_YR            INTEGER                      4   \n",
       "62    IMM_DIM_PSN            INS_ID            INTEGER                      6   \n",
       "69    IMM_DIM_PSN        ADR_RGN_CD            CHAR(2)                      2   \n",
       "75   IMM_DIM_VISA            IMM_ID            INTEGER                      4   \n",
       "76   IMM_DIM_VISA        VISA_TP_CD            CHAR(2)                      2   \n",
       "78   IMM_DIM_VISA  VISA_ISSU_DEP_CD            CHAR(3)                      3   \n",
       "77   IMM_DIM_VISA       VISA_RSN_CD            INTEGER                      1   \n",
       "58        IMM_FCT            DEP_CD            CHAR(1)                      1   \n",
       "59        IMM_FCT            DEP_DT  DATE 'YYYY-MM-DD'                     10   \n",
       "53        IMM_FCT            IMM_ID            INTEGER                      4   \n",
       "60        IMM_FCT        ADM_UPD_CD            CHAR(1)                      1   \n",
       "55        IMM_FCT        ADM_MTD_CD            INTEGER                      1   \n",
       "56        IMM_FCT            ADM_NO            INTEGER                     10   \n",
       "57        IMM_FCT         ADM_TO_DT  DATE 'YYYY-MM-DD'                     10   \n",
       "54        IMM_FCT            ADM_CD            CHAR(1)                      1   \n",
       "48  TEMP_DIM_CITY          LONG_VAL       DECIMAL(5,3)                      5   \n",
       "47  TEMP_DIM_CITY           LAT_VAL       DECIMAL(4,2)                      4   \n",
       "46  TEMP_DIM_CITY            CTY_NM       VARCHAR(255)                    255   \n",
       "45  TEMP_DIM_CITY           CITY_NM       VARCHAR(255)                    255   \n",
       "44  TEMP_DIM_CITY      TEMP_CITY_ID            INTEGER                      4   \n",
       "52       TEMP_FCT       TEMP_SD_VAL       DECIMAL(5,3)                      5   \n",
       "51       TEMP_FCT      TEMP_AVG_VAL       DECIMAL(5,3)                      5   \n",
       "49       TEMP_FCT      TEMP_CITY_ID            INTEGER                      4   \n",
       "50       TEMP_FCT            MSR_DT  DATE 'YYYY-MM-DD'                     10   \n",
       "\n",
       "                                          Description  \\\n",
       "20                     ISO Country code, 2 characters   \n",
       "17                                    Name of airport   \n",
       "18       Elevation of airport above sea level in feet   \n",
       "19  2-letter code of continent, e.g. NA for North ...   \n",
       "21  4-letter code of region in format \"country - S...   \n",
       "15       Airport ID consisting of letters and numbers   \n",
       "16  Type of airport, including \"Closed\" in case it...   \n",
       "23               GPS location code - see also ARPT_ID   \n",
       "24   IATA airport code, similar to ARPT_ID and GPS_CD   \n",
       "25  Local airport code, similar to ARPT_ID, GPS_CD...   \n",
       "26                                           Latitude   \n",
       "27                                          Longitude   \n",
       "22                               Name of municipality   \n",
       "7                 Method code taking on 1, 2, 3, or 9   \n",
       "8   Description of whether immigrant came by Air, ...   \n",
       "11                          Code for admission status   \n",
       "12                   Description for admission status   \n",
       "0                  Airport CD consisting of 3 letters   \n",
       "1   Airport name (typically the name of the city)....   \n",
       "2       2-letter code for the state the airport is in   \n",
       "6                                        Country name   \n",
       "5         Country code consisting of up to 3 integers   \n",
       "13                          Code for departure reason   \n",
       "14  Description for departure reason - the letter ...   \n",
       "42                             4-letter code for race   \n",
       "43                     Race relating to the race code   \n",
       "3                         Code for US state or region   \n",
       "4                          Name of US State or region   \n",
       "9             Code for reason for applying for a visa   \n",
       "10     Description for reason for applying for a visa   \n",
       "28             Identification (serial) number of city   \n",
       "30             Name for region - typically a US state   \n",
       "31                                       Name of city   \n",
       "32                                 Median age in city   \n",
       "33                           Total population in city   \n",
       "34                      Total male population in city   \n",
       "35                    Total female population in city   \n",
       "36                   Total veteran population in city   \n",
       "37              Total foreign-born population in city   \n",
       "38                  Average size of household in city   \n",
       "29    2-letter code for region - typically a US state   \n",
       "39                City ID, same as for DEMO_FCT table   \n",
       "40                             4-letter code for race   \n",
       "41  Total population of specific race for specific...   \n",
       "74           Date of arrival in the US, not admission   \n",
       "73  5 character code for flight number of arrival ...   \n",
       "72  2-letter code for airline of arrival flight to...   \n",
       "71  3-letter code for airport city of arrival flig...   \n",
       "70                                Immigration case ID   \n",
       "61                                Immigration case ID   \n",
       "68                   ID of country of prior residence   \n",
       "67                 ID of country of prior citizenship   \n",
       "66  One-letter code for (M)ale, (F)emale or (U)nknown   \n",
       "65  Three letter code for occupation - not decoded...   \n",
       "64                                       Age in years   \n",
       "63                                      Year of birth   \n",
       "62  Insurance ID, takes on -1 in the event it is u...   \n",
       "69               State code of immigrants new address   \n",
       "75                                Immigration case ID   \n",
       "76      2-letter code for VISA obtained - not decoded   \n",
       "78             3-letter code for issuing city of VISA   \n",
       "77  1 digit code for VISA application reason - dec...   \n",
       "58                               Reason for departure   \n",
       "59                                  Date of departure   \n",
       "53                                Immigration case ID   \n",
       "60                         Code for admission updates   \n",
       "55     1-letter code explaining the entry into the US   \n",
       "56        An admission number which is technical only   \n",
       "57  End date until when the admitted person can st...   \n",
       "54  1-letter code explaining the cause of admissio...   \n",
       "48                                          Longitude   \n",
       "47                                           Latitude   \n",
       "46                                    Name of country   \n",
       "45                                       Name of city   \n",
       "44    Id for city in temperature data set (serial id)   \n",
       "52  Average temperature uncertainty (standard devi...   \n",
       "51              Average temperature for date for city   \n",
       "49    Id for city in temperature data set (serial id)   \n",
       "50                   Date of temperature measuremenet   \n",
       "\n",
       "                              Example  \n",
       "20                                 US  \n",
       "17               Alpine Range Airport  \n",
       "18                             670.00  \n",
       "19                                 NA  \n",
       "21                              US-TX  \n",
       "15                               00TS  \n",
       "16                      Small Airport  \n",
       "23                               00TS  \n",
       "24                               00TS  \n",
       "25                               00TS  \n",
       "26                              32.61  \n",
       "27                             -97.24  \n",
       "22                            Everman  \n",
       "7                                   3  \n",
       "8                                Land  \n",
       "11                                  G  \n",
       "12                   Admitted into US  \n",
       "0                                 ANC  \n",
       "1                           ANCHORAGE  \n",
       "2                                  AK  \n",
       "6                         AFGHANISTAN  \n",
       "5                                 236  \n",
       "13                                  D  \n",
       "14                      Alien crewman  \n",
       "42                               AIAN  \n",
       "43  American Indian and Alaska Native  \n",
       "3                                  AK  \n",
       "4                              ALASKA  \n",
       "9                                   1  \n",
       "10                           Business  \n",
       "28                                  1  \n",
       "30                           Missouri  \n",
       "31                       Independence  \n",
       "32                               38.6  \n",
       "33                             117255  \n",
       "34                              54348  \n",
       "35                              62907  \n",
       "36                              10220  \n",
       "37                               4911  \n",
       "38                               2.33  \n",
       "29                                 MO  \n",
       "39                                447  \n",
       "40                               BLAA  \n",
       "41                             138242  \n",
       "74                         2016-04-01  \n",
       "73                              00089  \n",
       "72                                 OS  \n",
       "71                                ATL  \n",
       "70                                 30  \n",
       "61                                127  \n",
       "68                                103  \n",
       "67                                103  \n",
       "66                                  F  \n",
       "65                                XXX  \n",
       "64                                 25  \n",
       "63                               1991  \n",
       "62                             545507  \n",
       "69                                 NJ  \n",
       "75                                265  \n",
       "76                                 WT  \n",
       "78                               None  \n",
       "77                                  2  \n",
       "58                                  O  \n",
       "59                         2016-04-09  \n",
       "53                                 93  \n",
       "60                               None  \n",
       "55                                  1  \n",
       "56                         2147483647  \n",
       "57                         2016-06-29  \n",
       "54                                  G  \n",
       "48                            -116.76  \n",
       "47                              34.56  \n",
       "46                      United States  \n",
       "45                            Ontario  \n",
       "44                                  1  \n",
       "52                              2.227  \n",
       "51                              2.773  \n",
       "49                               1537  \n",
       "50                         1750-03-01  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', len(all_dict_df))\n",
    "all_dict_df.sort_values(by=['Table'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 6. Data quality checks\n",
    "\n",
    "We should assess two sets of quality checks: \n",
    "1. The quality of each data in separation\n",
    "2. The quality of data after join\n",
    "\n",
    "Since we have set join keys it is natural to see if they perform at all and how well they perform. If data is lost there is either a data integrity issue or the key is inappropriate.\n",
    "\n",
    "As an example of a key that is not inappropriate yet holds a data integrity issue we can name latitude and longitude fields between the temperature data set and the airport data set. Because temperatures aren't generally measured at airports we can't expect the join to perform well. Where temperatures are taken at airports the join should perform well.\n",
    "\n",
    "Another key which is expected to have data integrity issues is the ADM_CD which holds reasons for admission. Because we do not have a full data description of source data we do not have a description for each value. Here we should enter the missing code descriptions into the DIM_ADM_CD even if there is no description.\n",
    "\n",
    "An example of an inappropriate key set is the ADM_CD field in DIM_ADM_CD to be joint on DEP_CD in FCT. This was suggested in the Q&A Platform but wouldn't work since they keys are non-overlapping.\n",
    "\n",
    "**The check**\n",
    "\n",
    "The checks can be any degree of sophisticated. We do a Proof of Concept here just by checking if each table on it's own has any rows and if each paired table returns any rows. Any amount of rows passes. In some instances an inner join should not provide any loss of records, e.g. the aforementioned ADM_CD, if written correctly, should not let a table lose any records when joined upon.\n",
    "\n",
    "**The order**\n",
    "\n",
    "The checks will be created for each table then be combined for one large dictionary. The order of creation will be as follows:\n",
    "0. Code tables built from text files and Google searches\n",
    "1. Airport data\n",
    "2. Demograhics data\n",
    "3. Temperature data\n",
    "4. Immigration data\n",
    "\n",
    "**The test function**\n",
    "We have a test function, *count_rows*, that counts the rows for multiple conditions:\n",
    "1. The amount of rows in a simple query\n",
    "2. The amount of rows when a conditional field is required not to be null\n",
    "3. The amount of rows when inner joining another table\n",
    "\n",
    "The results can be:\n",
    "1. Passed, which means there are positive rows for the simple query and no loss of rows for all others\n",
    "2. Warning, which means that there is a loss or duplication of rows on queries that are not the simple query relative to the simple query\n",
    "3. Fail, which means the query returns no rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def count_rows(spark_df, cond_fld=None, join_dict=None):\n",
    "    '''\n",
    "    Description\n",
    "    -----------\n",
    "    This function takes a spark dataframe and performs\n",
    "    queries on this to count the records. If a condition\n",
    "    field is inputted, it will count records with no nulls\n",
    "    on that field. If a join dictionary is provided it will\n",
    "    count records outputted for each table after inner joining\n",
    "    with the spark dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    spark_df : str\n",
    "        The name of a Spark Data Frame from the data model.\n",
    "    \n",
    "    cond_fld : str\n",
    "        A string representing a field in the spark dataframe\n",
    "        that is required to not be null.\n",
    "    \n",
    "    join_dict : dictionary\n",
    "        A dictionary where all keys are tables to join on the\n",
    "        spark dataframe, and which requires the values to be\n",
    "        dictionaries consisting of a \"left_join_fld\" and a \n",
    "        \"right_join_fld\" with the former being the join field\n",
    "        from the spark dataframe and the latter being the join\n",
    "        field from the join table.\n",
    "        \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dic : dictionary\n",
    "        A dictionary containing the tests as keys and their \n",
    "        row counts as values.\n",
    "    '''\n",
    "    base_qry = f'SELECT * FROM {spark_df}'\n",
    "    return_dict = {}\n",
    "    \n",
    "    # Make base query\n",
    "    print('Querying base table: ' + spark_df)\n",
    "    base_row_count = spark.sql(base_qry).count()\n",
    "    return_dict['base_row_count'] = base_row_count\n",
    "    \n",
    "    if cond_fld is not None:\n",
    "        cond_qry = base_qry + f' WHERE {cond_fld} IS NOT NULL'\n",
    "    \n",
    "        # Make conditional query\n",
    "        print('Querying conditional table: ' + spark_df)\n",
    "        cond_row_count = spark.sql(cond_qry).count()\n",
    "        return_dict['cond_row_count'] = cond_row_count\n",
    "    \n",
    "    if join_dict is not None:    \n",
    "        for k, v in join_dict.items():\n",
    "            print(f'Get join conditions for table {k}: ')\n",
    "\n",
    "            try:\n",
    "                jt = k\n",
    "                ljf = v['left_join_fld']\n",
    "                rjf = v['right_join_fld']\n",
    "            except KeyError as e:\n",
    "                print('Key is missing.')\n",
    "                print(e)\n",
    "\n",
    "            print('Querying join statement')\n",
    "            join_qry = f'SELECT * FROM {spark_df} AS mt \\\n",
    "              INNER JOIN {jt} AS jt \\\n",
    "              ON mt.{ljf} = jt.{rjf}'\n",
    "\n",
    "            join_row_count = spark.sql(join_qry).count()\n",
    "            return_dict[k] = join_row_count\n",
    "    \n",
    "    for k, v in return_dict.items():\n",
    "        if v == 0:\n",
    "            print('Failed: Test ' + k + ' has no records.')\n",
    "        elif v < base_row_count:\n",
    "            print('Warning: Test ' + k + ' has passed but records have been lost.' )\n",
    "        elif v > base_row_count:\n",
    "            print('Warning: Test ' + k + ' has passed but records have been duplicated.')\n",
    "        else:\n",
    "            print('Success: Test ' + k + ' has passed with no lost records.')\n",
    "            \n",
    "        print('Query ' + k + ' has ' + str(v) + ' rows.')\n",
    "    \n",
    "    print('Tests done.')\n",
    "    return(return_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 6.1 Immigration\n",
    "\n",
    "We will test the following:\n",
    "1. Fct\n",
    "  1. Join on ADM_CD\n",
    "  2. Join on ADM_MTD_CD\n",
    "  3. Join on DEP_CD\n",
    "  4. Join on ADM_UPD_CD\n",
    "2. Person dimension\n",
    "  1. Join on CTY_OF_CTZ_ID\n",
    "  2. Join on CTY_OF_RSDN_ID\n",
    "  3. Join on RGN_CD\n",
    "3. Airport dimension\n",
    "  1. Join on ARPT_CD\n",
    "4. Visa dimension\n",
    "  1. Join on VISA_RSN_CD\n",
    "  2. Join on VISA_ISSU_DEP_CD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 6.1.1 FCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_fct.createOrReplaceTempView('IMM_FCT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(cd_adm_st).createOrReplaceTempView('cd_adm_st')\n",
    "spark.createDataFrame(cd_adm_mtd).createOrReplaceTempView('cd_adm_mtd')\n",
    "spark.createDataFrame(cd_dep).createOrReplaceTempView('cd_dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "join_dict = {\n",
    "    'CD_ADM_ST' : {'left_join_fld' : 'ADM_CD', 'right_join_fld' : 'ADM_ST_CD'},\n",
    "    'CD_ADM_MTD': {'left_join_fld' : 'ADM_MTD_CD', 'right_join_fld' : 'ADM_MTD_CD'},\n",
    "    'CD_DEP' : {'left_join_fld' : 'DEP_CD', 'right_join_fld' : 'DEP_CD'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying base table: imm_fct_df\n",
      "Querying conditional table: imm_fct_df\n",
      "Get join conditions for table CD_ADM_ST: \n",
      "Querying join statement\n",
      "Get join conditions for table CD_ADM_MTD: \n",
      "Querying join statement\n",
      "Get join conditions for table CD_DEP: \n",
      "Querying join statement\n",
      "Success: Test base_row_count has passed with no lost records.\n",
      "Query base_row_count has 3096313 rows.\n",
      "Success: Test cond_row_count has passed with no lost records.\n",
      "Query cond_row_count has 3096313 rows.\n",
      "Warning: Test CD_ADM_ST has passed but records have been lost.\n",
      "Query CD_ADM_ST has 2955975 rows.\n",
      "Warning: Test CD_ADM_MTD has passed but records have been lost.\n",
      "Query CD_ADM_MTD has 3096074 rows.\n",
      "Warning: Test CD_DEP has passed but records have been lost.\n",
      "Query CD_DEP has 2957884 rows.\n"
     ]
    }
   ],
   "source": [
    "ret_dict = count_rows('IMM_FCT', cond_fld='IMM_ID', join_dict=join_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 6.1.2 PSN_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_dim_psn.createOrReplaceTempView('IMM_DIM_PSN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(cd_cty).createOrReplaceTempView('CD_CTY')\n",
    "spark.createDataFrame(cd_rgn).createOrReplaceTempView('CD_RGN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "join_dict = {\n",
    "    'IMM_FCT' : {'left_join_fld' : 'IMM_ID', 'right_join_fld' : 'IMM_ID'},\n",
    "    'CD_CTY': {'left_join_fld' : 'CTY_OF_RSDN_ID', 'right_join_fld' : 'CTY_CD'},\n",
    "    'CD_RGN' : {'left_join_fld' : 'ADR_RGN_CD', 'right_join_fld' : 'RGN_CD'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying base table: IMM_DIM_PSN\n",
      "Querying conditional table: IMM_DIM_PSN\n",
      "Get join conditions for table IMM_FCT: \n",
      "Querying join statement\n",
      "Get join conditions for table CD_CTY: \n",
      "Querying join statement\n",
      "Get join conditions for table CD_RGN: \n",
      "Querying join statement\n",
      "Success: Test base_row_count has passed with no lost records.\n",
      "Query base_row_count has 3096313 rows.\n",
      "Success: Test cond_row_count has passed with no lost records.\n",
      "Query cond_row_count has 3096313 rows.\n",
      "Success: Test IMM_FCT has passed with no lost records.\n",
      "Query IMM_FCT has 3096313 rows.\n",
      "Success: Test CD_CTY has passed with no lost records.\n",
      "Query CD_CTY has 3096313 rows.\n",
      "Warning: Test CD_RGN has passed but records have been lost.\n",
      "Query CD_RGN has 2917199 rows.\n"
     ]
    }
   ],
   "source": [
    "ret_dict = count_rows('IMM_DIM_PSN', cond_fld='IMM_ID', join_dict=join_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 6.1.3 ARPT_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_dim_arpt.createOrReplaceTempView('IMM_DIM_ARPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(cd_arpt).createOrReplaceTempView('CD_ARPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "join_dict = {\n",
    "    'IMM_FCT' : {'left_join_fld' : 'IMM_ID', 'right_join_fld' : 'IMM_ID'},\n",
    "    'CD_ARPT': {'left_join_fld' : 'ARPT_CD', 'right_join_fld' : 'ARPT_CD'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying base table: IMM_DIM_ARPT\n",
      "Querying conditional table: IMM_DIM_ARPT\n",
      "Get join conditions for table IMM_FCT: \n",
      "Querying join statement\n",
      "Get join conditions for table CD_ARPT: \n",
      "Querying join statement\n",
      "Success: Test base_row_count has passed with no lost records.\n",
      "Query base_row_count has 3096313 rows.\n",
      "Success: Test cond_row_count has passed with no lost records.\n",
      "Query cond_row_count has 3096313 rows.\n",
      "Success: Test IMM_FCT has passed with no lost records.\n",
      "Query IMM_FCT has 3096313 rows.\n",
      "Success: Test CD_ARPT has passed with no lost records.\n",
      "Query CD_ARPT has 3096313 rows.\n"
     ]
    }
   ],
   "source": [
    "arpt_ret_dict = count_rows('IMM_DIM_ARPT', cond_fld='IMM_ID', join_dict=join_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 6.1.4 VISA_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_dim_visa.createOrReplaceTempView('IMM_DIM_VISA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(cd_visa_rsn).createOrReplaceTempView('CD_VISA_RSN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "join_dict = {\n",
    "    'IMM_FCT' : {'left_join_fld' : 'IMM_ID', 'right_join_fld' : 'IMM_ID'},\n",
    "    'CD_VISA_RSN': {'left_join_fld' : 'VISA_RSN_CD', 'right_join_fld' : 'VISA_RSN_CD'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying base table: IMM_DIM_VISA\n",
      "Querying conditional table: IMM_DIM_VISA\n",
      "Get join conditions for table IMM_FCT: \n",
      "Querying join statement\n",
      "Get join conditions for table CD_VISA_RSN: \n",
      "Querying join statement\n",
      "Success: Test base_row_count has passed with no lost records.\n",
      "Query base_row_count has 3096313 rows.\n",
      "Success: Test cond_row_count has passed with no lost records.\n",
      "Query cond_row_count has 3096313 rows.\n",
      "Success: Test IMM_FCT has passed with no lost records.\n",
      "Query IMM_FCT has 3096313 rows.\n",
      "Success: Test CD_VISA_RSN has passed with no lost records.\n",
      "Query CD_VISA_RSN has 3096313 rows.\n"
     ]
    }
   ],
   "source": [
    "visa_ret_dict = count_rows('IMM_DIM_VISA', cond_fld='IMM_ID', join_dict=join_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 6.2 Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 6.2.1 DEMO_FCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demo_fct.createOrReplaceTempView('DEMO_FCT')\n",
    "demo_fct_race.createOrReplaceTempView('DEMO_FCT_RACE')\n",
    "cd_race_tp.createOrReplaceTempView('CD_RACE_TP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "join_dict = {\n",
    "    'CD_RGN' : {'left_join_fld' : 'RGN_CD', 'right_join_fld' : 'RGN_CD'},\n",
    "    'DEMO_FCT_RACE': {'left_join_fld' : 'DEMO_CITY_ID', 'right_join_fld' : 'DEMO_CITY_ID'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying base table: DEMO_FCT\n",
      "Querying conditional table: DEMO_FCT\n",
      "Get join conditions for table CD_RGN: \n",
      "Querying join statement\n",
      "Get join conditions for table DEMO_FCT_RACE: \n",
      "Querying join statement\n",
      "Success: Test base_row_count has passed with no lost records.\n",
      "Query base_row_count has 596 rows.\n",
      "Success: Test cond_row_count has passed with no lost records.\n",
      "Query cond_row_count has 596 rows.\n",
      "Success: Test CD_RGN has passed with no lost records.\n",
      "Query CD_RGN has 596 rows.\n",
      "Warning: Test DEMO_FCT_RACE has passed but records have been duplicated.\n",
      "Query DEMO_FCT_RACE has 2891 rows.\n"
     ]
    }
   ],
   "source": [
    "demo_fct_ret_dict = count_rows('DEMO_FCT', cond_fld='DEMO_CITY_ID', join_dict=join_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 6.2.2 DEMO_FCT_RACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "join_dict = {\n",
    "    'CD_RACE_TP': {'left_join_fld' : 'RACE_TP_CD', 'right_join_fld' : 'RACE_TP_CD'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying base table: DEMO_FCT_RACE\n",
      "Querying conditional table: DEMO_FCT_RACE\n",
      "Get join conditions for table CD_RACE_TP: \n",
      "Querying join statement\n",
      "Success: Test base_row_count has passed with no lost records.\n",
      "Query base_row_count has 2891 rows.\n",
      "Success: Test cond_row_count has passed with no lost records.\n",
      "Query cond_row_count has 2891 rows.\n",
      "Success: Test CD_RACE_TP has passed with no lost records.\n",
      "Query CD_RACE_TP has 2891 rows.\n"
     ]
    }
   ],
   "source": [
    "demo_fct_race_ret_dict = count_rows('DEMO_FCT_RACE', cond_fld='RACE_TP_CD', join_dict=join_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 6.3 Airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "arpt_fct.createOrReplaceTempView('ARPT_FCT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "join_dict = {\n",
    "    'IMM_DIM_VISA' : {'left_join_fld' : 'IATA_ARPT_CD', 'right_join_fld' : 'VISA_ISSU_DEP_CD'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying base table: ARPT_FCT\n",
      "Querying conditional table: ARPT_FCT\n",
      "Get join conditions for table IMM_DIM_VISA: \n",
      "Querying join statement\n",
      "Success: Test base_row_count has passed with no lost records.\n",
      "Query base_row_count has 55075 rows.\n",
      "Success: Test cond_row_count has passed with no lost records.\n",
      "Query cond_row_count has 55075 rows.\n",
      "Warning: Test IMM_DIM_VISA has passed but records have been duplicated.\n",
      "Query IMM_DIM_VISA has 939955 rows.\n",
      "Tests done.\n"
     ]
    }
   ],
   "source": [
    "arpt_fct_ret_dict = count_rows('ARPT_FCT', cond_fld='ARPT_ID', join_dict=join_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 6.4 Temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_fct.createOrReplaceTempView('TEMP_FCT')\n",
    "temp_dim_city.createOrReplaceTempView('TEMP_DIM_CITY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "join_dict = {\n",
    "    'TEMP_DIM_CITY' : {'left_join_fld' : 'TEMP_CITY_ID', 'right_join_fld' : 'TEMP_CITY_ID'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying base table: TEMP_FCT\n",
      "Querying conditional table: TEMP_FCT\n",
      "Get join conditions for table TEMP_DIM_CITY: \n",
      "Querying join statement\n",
      "Success: Test base_row_count has passed with no lost records.\n",
      "Query base_row_count has 8598145 rows.\n",
      "Success: Test cond_row_count has passed with no lost records.\n",
      "Query cond_row_count has 8598145 rows.\n",
      "Success: Test TEMP_DIM_CITY has passed with no lost records.\n",
      "Query TEMP_DIM_CITY has 8598145 rows.\n",
      "Tests done.\n"
     ]
    }
   ],
   "source": [
    "temp_fct_ret_dict = count_rows('TEMP_FCT', cond_fld='TEMP_CITY_ID', join_dict=join_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 7. Redshift\n",
    "\n",
    "In the case the user wants to establish a redshift connection, the below steps can be followed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Following steps need to be taken:\n",
    "1. IAM client to \n",
    "  1. Create an IAM role\n",
    "  2. Attach IAM role to IAM user\n",
    "2. Create Redshift client\n",
    "  1. Create Redshift cluster\n",
    "3. Create ec2 client\n",
    "  1. Establish VPC connection to redshift\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 7.1 The IAM Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 7.1.1 Creating the IAM client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "iam = boto3.client(\n",
    "    'iam',\n",
    "    aws_access_key_id=KEY,\n",
    "    aws_secret_access_key=SECRET,\n",
    "    region_name=REGION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 7.1.2 Create IAM role\n",
    "This assumes an IAM user has already been created in AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new IAM Role\n",
      "Error: The IAM role is already created.\n",
      "An error occurred (EntityAlreadyExists) when calling the CreateRole operation: Role with name dwhadmin already exists.\n"
     ]
    }
   ],
   "source": [
    "DWH_IAM_ROLE_NAME = config.get('DWH', 'DWH_IAM_ROLE_NAME')\n",
    "\n",
    "try:\n",
    "    print(\"Creating a new IAM Role\") \n",
    "    dwhRole = iam.create_role(\n",
    "        Path='/',\n",
    "        RoleName=DWH_IAM_ROLE_NAME,\n",
    "        Description='Allows Redshift clusters to call AWS services on your behalf.',\n",
    "        AssumeRolePolicyDocument=json.dumps(\n",
    "            {\n",
    "                'Statement': [{\n",
    "                    'Action': 'sts:AssumeRole',\n",
    "                    'Effect': 'Allow',\n",
    "                    'Principal': {'Service': 'redshift.amazonaws.com'}\n",
    "                }],\n",
    "                'Version': '2012-10-17'\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "except iam.exceptions.EntityAlreadyExistsException as e: \n",
    "    print(\"Error: The IAM role is already created.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 7.1.3 Attach IAM role policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2 Attaching Policy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"1.2 Attaching Policy\")\n",
    "iam.attach_role_policy(\n",
    "    RoleName=DWH_IAM_ROLE_NAME,\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess'\n",
    ")['ResponseMetadata']['HTTPStatusCode']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We want to establish a connection to a Redshift cluster where we can create the tables and populate them with data. We will set up a Redshift cluster programmatically, but first we need to make sure the basics are handled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 7.2 The Redshift cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 7.2.1 Create Redshift client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "redshift = boto3.client(\n",
    "    'redshift',\n",
    "    region_name='us-west-2',\n",
    "    aws_access_key_id=KEY,\n",
    "    aws_secret_access_key=SECRET\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 7.2.2 Create redshift cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The cluster is already created\n",
      "An error occurred (ClusterAlreadyExists) when calling the CreateCluster operation: Cluster already exists\n"
     ]
    }
   ],
   "source": [
    "# HW\n",
    "DWH_CLUSTER_TYPE       = config.get('DWH', 'DWH_CLUSTER_TYPE')\n",
    "DWH_NODE_TYPE          = config.get(\"DWH\",\"DWH_NODE_TYPE\")\n",
    "DWH_NUM_NODES          = config.get(\"DWH\",\"DWH_NUM_NODES\")\n",
    "\n",
    "# Identifiers & Credentials\n",
    "DWH_DB                 = config.get(\"DWH\",\"DWH_DB\")\n",
    "DWH_CLUSTER_IDENTIFIER = config.get(\"DWH\",\"DWH_CLUSTER_IDENTIFIER\")\n",
    "DWH_DB_USER            = config.get(\"DWH\",\"DWH_DB_USER\")\n",
    "DWH_DB_PASSWORD        = config.get(\"DWH\",\"DWH_DB_PASSWORD\")\n",
    "\n",
    "roleArn = iam.get_role(RoleName=DWH_IAM_ROLE_NAME)['Role']['Arn']\n",
    "\n",
    "try:\n",
    "    redshift.create_cluster(\n",
    "        # HW\n",
    "        ClusterType        = DWH_CLUSTER_TYPE,\n",
    "        NodeType           = DWH_NODE_TYPE,\n",
    "        NumberOfNodes      = int(DWH_NUM_NODES),\n",
    "\n",
    "        # Identifiers & Credentials\n",
    "        DBName             = DWH_DB,\n",
    "        ClusterIdentifier  = DWH_CLUSTER_IDENTIFIER,\n",
    "        MasterUsername     = DWH_DB_USER,\n",
    "        MasterUserPassword = DWH_DB_PASSWORD,\n",
    "\n",
    "        #Roles (for s3 access)\n",
    "        IamRoles           = [roleArn]\n",
    "    )\n",
    "except redshift.exceptions.ClusterAlreadyExistsFault as e: \n",
    "    print(\"Error: The cluster is already created\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 7.2.3 Describe cluster\n",
    "In this description we note that we can see when the cluster is available. Until status says available we should only proceed where meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def prettyRedshiftProps(props):\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    keysToShow = [\"ClusterIdentifier\", \"NodeType\", \"ClusterStatus\", \"MasterUsername\", \"DBName\", \"Endpoint\", \"NumberOfNodes\", 'VpcId']\n",
    "    x = [(k, v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns=[\"Key\", \"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>dwhcluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'dwhcluster.chwnsn8m2dbb.us-west-2.redshift.amazonaws.com', 'Port': 5439}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-73f0f80b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key  \\\n",
       "0  ClusterIdentifier   \n",
       "1  NodeType            \n",
       "2  ClusterStatus       \n",
       "3  MasterUsername      \n",
       "4  DBName              \n",
       "5  Endpoint            \n",
       "6  VpcId               \n",
       "7  NumberOfNodes       \n",
       "\n",
       "                                                                                   Value  \n",
       "0  dwhcluster                                                                             \n",
       "1  dc2.large                                                                              \n",
       "2  available                                                                              \n",
       "3  dwhuser                                                                                \n",
       "4  dwh                                                                                    \n",
       "5  {'Address': 'dwhcluster.chwnsn8m2dbb.us-west-2.redshift.amazonaws.com', 'Port': 5439}  \n",
       "6  vpc-73f0f80b                                                                           \n",
       "7  4                                                                                      "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 7.2.4 Describe cluster endpoint and IAM role arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWH_ENDPOINT ::  dwhcluster.chwnsn8m2dbb.us-west-2.redshift.amazonaws.com\n",
      "DWH_ROLE_ARN ::  arn:aws:iam::355814333192:role/dwhadmin\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    DWH_ENDPOINT = myClusterProps['Endpoint']['Address']\n",
    "    DWH_ROLE_ARN = myClusterProps['IamRoles'][0]['IamRoleArn']\n",
    "    print(\"DWH_ENDPOINT :: \", DWH_ENDPOINT)\n",
    "    print(\"DWH_ROLE_ARN :: \", DWH_ROLE_ARN)\n",
    "except KeyError as e:\n",
    "    print(\"Check that cluster has been created (is available) - can't locate Endpoint if not.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 7.2.5 Open an incoming TCP port to access the cluster endpoint\n",
    "Reading and writing to Redshift requires an open TCP port."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 7.2.5.1 Create EC2 client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "ec2 = boto3.resource(\n",
    "    'ec2',\n",
    "    region_name=\"us-west-2\",\n",
    "    aws_access_key_id=KEY,\n",
    "    aws_secret_access_key=SECRET\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-002a328934a579da2')\n",
      "An error occurred (InvalidPermission.Duplicate) when calling the AuthorizeSecurityGroupIngress operation: the specified rule \"peer: 0.0.0.0/0, TCP, from port: 5439, to port: 5439, ALLOW\" already exists\n",
      "If error is that port already exists then Okay.\n"
     ]
    }
   ],
   "source": [
    "VPC_ID = myClusterProps['VpcId']\n",
    "DWH_PORT = config.get('DWH', 'DWH_PORT')\n",
    "\n",
    "try:\n",
    "    vpc = ec2.Vpc(id=VPC_ID)\n",
    "    defaultSg = list(vpc.security_groups.all())[0]\n",
    "    print(defaultSg)\n",
    "    defaultSg.authorize_ingress(\n",
    "        #GroupName=defaultSg.group_name,\n",
    "        GroupName='default',\n",
    "        CidrIp='0.0.0.0/0',\n",
    "        IpProtocol='TCP',\n",
    "        FromPort=int(DWH_PORT),\n",
    "        ToPort=int(DWH_PORT)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"If error is that port already exists then Okay.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<connection object at 0x7fc6ab3313d8; dsn: 'user=dwhuser password=xxx dbname=dwh host=dwhcluster.chwnsn8m2dbb.us-west-2.redshift.amazonaws.com port=5439', closed: 0>\n"
     ]
    }
   ],
   "source": [
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DWH_DB_USER, DWH_DB_PASSWORD, DWH_ENDPOINT, DWH_PORT,DWH_DB)\n",
    "try:\n",
    "    conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "    cur = conn.cursor()\n",
    "    print(conn)\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Could not make connection to the Postgres database\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'postgresql://dwhuser:Passw0rd@dwhcluster.chwnsn8m2dbb.us-west-2.redshift.amazonaws.com:5439/dwh'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connected: dwhuser@dwh'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 7.3 Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 7.3.1 Delete cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cluster': {'ClusterIdentifier': 'dwhcluster',\n",
       "  'NodeType': 'dc2.large',\n",
       "  'ClusterStatus': 'deleting',\n",
       "  'MasterUsername': 'dwhuser',\n",
       "  'DBName': 'dwh',\n",
       "  'Endpoint': {'Address': 'dwhcluster.chwnsn8m2dbb.us-west-2.redshift.amazonaws.com',\n",
       "   'Port': 5439},\n",
       "  'ClusterCreateTime': datetime.datetime(2022, 6, 4, 20, 36, 9, 103000, tzinfo=tzlocal()),\n",
       "  'AutomatedSnapshotRetentionPeriod': 1,\n",
       "  'ClusterSecurityGroups': [],\n",
       "  'VpcSecurityGroups': [{'VpcSecurityGroupId': 'sg-fc8e7ff7',\n",
       "    'Status': 'active'}],\n",
       "  'ClusterParameterGroups': [{'ParameterGroupName': 'default.redshift-1.0',\n",
       "    'ParameterApplyStatus': 'in-sync'}],\n",
       "  'ClusterSubnetGroupName': 'default',\n",
       "  'VpcId': 'vpc-73f0f80b',\n",
       "  'AvailabilityZone': 'us-west-2d',\n",
       "  'PreferredMaintenanceWindow': 'wed:13:30-wed:14:00',\n",
       "  'PendingModifiedValues': {},\n",
       "  'ClusterVersion': '1.0',\n",
       "  'AllowVersionUpgrade': True,\n",
       "  'NumberOfNodes': 4,\n",
       "  'PubliclyAccessible': True,\n",
       "  'Encrypted': False,\n",
       "  'Tags': [],\n",
       "  'EnhancedVpcRouting': False,\n",
       "  'IamRoles': [{'IamRoleArn': 'arn:aws:iam::355814333192:role/dwhadmin',\n",
       "    'ApplyStatus': 'in-sync'}],\n",
       "  'MaintenanceTrackName': 'current'},\n",
       " 'ResponseMetadata': {'RequestId': '6f6eb04f-0233-4fc0-8b74-bf93d3a43ba2',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '6f6eb04f-0233-4fc0-8b74-bf93d3a43ba2',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '2686',\n",
       "   'vary': 'accept-encoding',\n",
       "   'date': 'Sat, 04 Jun 2022 21:19:10 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# redshift.delete_cluster(\n",
    "#     ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,\n",
    "#     SkipFinalClusterSnapshot=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 7.3.2 Detach IAM role from IAM user and delete the role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#### CAREFUL!!\n",
    "#-- Uncomment & run to delete the created resources\n",
    "iam.detach_role_policy(RoleName=DWH_IAM_ROLE_NAME, PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\")\n",
    "iam.delete_role(RoleName=DWH_IAM_ROLE_NAME)\n",
    "#### CAREFUL!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 8. Conclusion\n",
    "Loading tables to Redshift was out of scope, but we managed to load tables to S3 and our quality checks highlighted issues in some departments for joining the code tables.\n",
    "\n",
    "Further steps would be to:\n",
    "- Improve partition of the temperature data set in particular.\n",
    "- Fill missing codes in code tables\n",
    "- Create further quality checks\n",
    "- Set up a data pipeline in e.g. Airflow where quality checks and further are included\n",
    "- Move staging tables to S3 and do Data Model transformations on Redshift - again through Airflow\n",
    "- Set up a Dashboard to illustrate all data\n",
    "\n",
    "#### Skewness and partitioning as data volume increases\n",
    "As the size of data sets increases further attention should be paid to data partitioning. We saw that it caused an issue for the temperature data set and it would also cause a problem for other data sets. Here we could do a `df.field.value_counts()` to look for skewness and consequently partition wisely to ensure an even distribution across workers.\n",
    "\n",
    "#### Daily run of pipelines at 7am\n",
    "Here we would use a scheduling tool such as Airflow to ensure reliable availability of data to all analysts. Here we can schedule loads of data and quality checks and beyond to not only ensure availability, but quality also.\n",
    "\n",
    "#### Large user base\n",
    "In the case that 100+ people will need to rely on the data model built above we could deploy the data model across multiple availability zones by deploying to multiple EC2 instances. Once the user base goes into the thousands we could simply store data in S3 buckets where users access the data using RESTful API's. This solution will be more cost-efficient relative to EC2.\n",
    "\n",
    "#### Final comments on Redshift\n",
    "For Redshift, we already have the table schemas in place and the connection made, so loading to here will be fairly straightforward. I ran out of credit on my free tier account with AWS and also with Udacity, so I stopped before having to pay too much in cloud usage. Had I had more credit and more time I could have continued with the Airflow and Redshift setup.\n",
    "\n",
    "#### Final comments on write-to-S3\n",
    "Since I exhausted my free tier with AWS (both through Udacity and through my personal access also) before having fixed some typos I had to comment out some write_to_S3 calls. This was particularly unfortunate for the temperature dataset, where I was still analysing data skewness to find the optimal partition when writing to S3. The call that used up my free tier was on the temperature dataset and had been running for 30+ minutes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
